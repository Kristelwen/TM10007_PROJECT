{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcFMDhNbjXFzWCc1hjv3VH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kristelwen/TM10007_PROJECT/blob/master/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5frTx3De-hD",
        "colab_type": "text"
      },
      "source": [
        "## TM10007 Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlW924rpgGbw",
        "colab_type": "code",
        "outputId": "3586da9e-b0fd-4c03-8015-6e9e4a9fe85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/Kristelwen/TM10007_PROJECT"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e11wSGohfFk_",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd46bOMwe3Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing modules\n",
        "# General packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from sklearn import datasets as ds\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Preprocessing packages\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# SVM Kernels\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Regularization\n",
        "from sklearn.linear_model import Lasso, RidgeClassifier\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTe-2RU5fK-q",
        "colab_type": "code",
        "outputId": "81ec5681-ca46-4cab-d991-29f3557130a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "# from adni.load_data import load_data\n",
        "from brats.load_data import load_data\n",
        "#from hn.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 167\n",
            "The number of columns: 725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld6uTA6nfPb1",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYhZfj2YfQux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop columns which contain NaN values\n",
        "threshold = math.floor(len(data)/2)  # calculate threshold, half of total rows\n",
        "data_drop = data.dropna(thresh=threshold, axis=1)  # Delete columns/features with more than 'threshold' NaNs\n",
        "data_drop = data_drop.dropna(axis=0)  # Delete rows/subjects with NaNs\n",
        "\n",
        "# Split data and labels\n",
        "labels = data_drop['label']\n",
        "data_drop = data_drop.drop(columns=\"label\")  # Data without labels\n",
        "\n",
        "# Convert labels 'GBM' and 'LGG' to respectively 0 and 1\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Delete columns with strings (2 columns)\n",
        "# data_strings = data_drop.select_dtypes(include=[object])\n",
        "# columns_strings = list(data_strings.columns)\n",
        "# data_no_strings = data_drop.drop(columns_strings, axis=1)\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "#data_no_strings = data_no_strings.replace([np.inf, -np.inf], np.nan)\n",
        "# print(np.isinf(data_no_strings.values).any()) - check if dataframe contains infinity values\n",
        "\n",
        "# Split the data in a train (80%) and test set (20%) - OF MOET DIT VOOR FEATURE SCALING? Omdat je niks mag fitten op testdata\n",
        "data_train, data_test, label_train, label_test = train_test_split(data_drop, labels, test_size=0.1)\n",
        "data_train2, data_val, label_train2, label_val = train_test_split(data_train, label_train, test_size=0.1)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = RobustScaler()\n",
        "transformer = scaler.fit(data_train2.values)\n",
        "data_scaled_train2 = transformer.transform(data_train2.values)\n",
        "data_df_train2 = pd.DataFrame(data_scaled_train2, index = data_train2.index, columns = data_train2.columns)\n",
        "\n",
        "data_scaled_val = transformer.transform(data_val.values)\n",
        "data_df_val = pd.DataFrame(data_scaled_val, index = data_val.index, columns = data_val.columns)\n",
        "\n",
        "data_scaled_test = transformer.transform(data_test.values)\n",
        "data_df_test = pd.DataFrame(data_scaled_test, index = data_test.index, columns = data_test.columns)\n",
        "\n",
        "# Optie 1 feature selection: PCA\n",
        "  # Training set 2\n",
        "pca_train = PCA(n_components=80)  # Create a PCA with 20 components\n",
        "pca_train.fit(data_scaled_train2)  # Fit PCA\n",
        "data_train_pca2 = pca_train.transform(data_scaled_train2)  # Transform train data using PCA\n",
        "#df_train_pca2 = pd.DataFrame(data_train_pca2, index = data_scaled_train2.index)  # Put train data back in dataframe with 20 most important features\n",
        " \n",
        "  # Training set 1\n",
        "#data_train_pca = pca_train.transform(data_train)\n",
        "  # Validatie set\n",
        "data_val_pca = pca_train.transform(data_scaled_val)  # Transform test data using PCA\n",
        "\n",
        "  # Test set\n",
        "data_test_pca = pca_train.transform(data_scaled_test)  # Transform test data using PCA\n",
        "\n",
        "# Optie 2 feature selection: RFECV\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5mSqn3FfRg_",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm0Pl-xthXat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing NN modules\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Cross-validation / performance\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6SX8BY3kiFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing -> train 1 wel scalen want cross validatie op toepassen\n",
        "transformer1 = scaler.fit(data_train.values)\n",
        "data_scaled_train = transformer1.transform(data_train.values)\n",
        "data_df_train = pd.DataFrame(data_scaled_train, index = data_train.index, columns = data_train.columns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qngmmSa8srqn",
        "colab_type": "code",
        "outputId": "2969c26b-5987-44f2-fd2b-66a40cadb586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "# Hyperparameter optimization of Neural Network\n",
        "\n",
        "# Define parameter space that needs to be optimized\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,), (7,2), (7,7,7),(9,9,9,9),(50,50,50,50), (50,50,50,50,50)],\n",
        "    'activation': ['logistic','identity','tanh'], \n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "# Create empty list\n",
        "fitted_mlps = list()\n",
        "    \n",
        "# Execute RandomizedSearchCV to find optimal parameters\n",
        "clf = RandomizedSearchCV(MLPClassifier(max_iter=2000), parameter_space, cv=5, random_state=42, return_train_score=True)  # Verbose=2 & refit=True uitzoeken\n",
        "\n",
        "# Fit the classifier\n",
        "clf.fit(data_train, label_train)\n",
        "\n",
        "# Save for next part\n",
        "fitted_mlps.append(clf)\n",
        "\n",
        "# Get the best parameters for the MLP estimator\n",
        "print('Best parameters found:\\n', clf.best_params_)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            " {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (7, 7, 7), 'alpha': 0.05, 'activation': 'identity'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ATmAmAE2Qz",
        "colab_type": "code",
        "outputId": "d19e0ca4-a367-44d8-cc48-e06052afe58e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "source": [
        "# Plot the dataframe of the hyperparameter optimization\n",
        "pd.DataFrame(clf.cv_results_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_solver</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_hidden_layer_sizes</th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>param_activation</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>split3_train_score</th>\n",
              "      <th>split4_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.370547</td>\n",
              "      <td>0.336066</td>\n",
              "      <td>0.004404</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>adam</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 2)</td>\n",
              "      <td>0.05</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'constant'...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.948804</td>\n",
              "      <td>0.950444</td>\n",
              "      <td>0.004881</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>sgd</td>\n",
              "      <td>constant</td>\n",
              "      <td>(100,)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>tanh</td>\n",
              "      <td>{'solver': 'sgd', 'learning_rate': 'constant',...</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.687464</td>\n",
              "      <td>0.032529</td>\n",
              "      <td>9</td>\n",
              "      <td>0.817308</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.752381</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.790476</td>\n",
              "      <td>0.814890</td>\n",
              "      <td>0.040199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.410722</td>\n",
              "      <td>0.019928</td>\n",
              "      <td>0.004710</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>sgd</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 2)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>identity</td>\n",
              "      <td>{'solver': 'sgd', 'learning_rate': 'constant',...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.114645</td>\n",
              "      <td>0.085951</td>\n",
              "      <td>0.004419</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>adam</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>(7, 2)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>tanh</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'adaptive'...</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.573219</td>\n",
              "      <td>0.133358</td>\n",
              "      <td>10</td>\n",
              "      <td>0.509615</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.647619</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.570495</td>\n",
              "      <td>0.144315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.388168</td>\n",
              "      <td>0.471474</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>adam</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 7, 7)</td>\n",
              "      <td>0.05</td>\n",
              "      <td>identity</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'constant'...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.717664</td>\n",
              "      <td>0.066428</td>\n",
              "      <td>1</td>\n",
              "      <td>0.971154</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.961905</td>\n",
              "      <td>0.923810</td>\n",
              "      <td>0.847619</td>\n",
              "      <td>0.927564</td>\n",
              "      <td>0.043630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.111796</td>\n",
              "      <td>0.031122</td>\n",
              "      <td>0.004343</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>adam</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 7, 7)</td>\n",
              "      <td>0.05</td>\n",
              "      <td>tanh</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'constant'...</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.709402</td>\n",
              "      <td>0.034188</td>\n",
              "      <td>2</td>\n",
              "      <td>0.759615</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.711923</td>\n",
              "      <td>0.024961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.260700</td>\n",
              "      <td>0.149117</td>\n",
              "      <td>0.004332</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>adam</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>(7, 2)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'adaptive'...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.332860</td>\n",
              "      <td>0.057417</td>\n",
              "      <td>0.004452</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>sgd</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>(7, 7, 7)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'sgd', 'learning_rate': 'adaptive',...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.345172</td>\n",
              "      <td>0.023982</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>sgd</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 7, 7)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'sgd', 'learning_rate': 'constant',...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.351032</td>\n",
              "      <td>0.078825</td>\n",
              "      <td>0.005424</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>adam</td>\n",
              "      <td>constant</td>\n",
              "      <td>(100,)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'constant'...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.702279</td>\n",
              "      <td>0.028533</td>\n",
              "      <td>3</td>\n",
              "      <td>0.701923</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.676190</td>\n",
              "      <td>0.704762</td>\n",
              "      <td>0.723810</td>\n",
              "      <td>0.700385</td>\n",
              "      <td>0.015376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n",
              "0       0.370547      0.336066  ...          0.694652         0.001172\n",
              "1       2.948804      0.950444  ...          0.814890         0.040199\n",
              "2       2.410722      0.019928  ...          0.694652         0.001172\n",
              "3       0.114645      0.085951  ...          0.570495         0.144315\n",
              "4       1.388168      0.471474  ...          0.927564         0.043630\n",
              "5       0.111796      0.031122  ...          0.711923         0.024961\n",
              "6       0.260700      0.149117  ...          0.694652         0.001172\n",
              "7       0.332860      0.057417  ...          0.694652         0.001172\n",
              "8       0.345172      0.023982  ...          0.694652         0.001172\n",
              "9       0.351032      0.078825  ...          0.700385         0.015376\n",
              "\n",
              "[10 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i31rjZMYhAI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting the Neural Network Classifier\n",
        "MLP = MLPClassifier(solver='adam', learning_rate='constant',hidden_layer_sizes=(9,9,9,9), alpha=0.0001, activation='identity')\n",
        "MLP.fit(data_df_train2, label_train2)\n",
        "\n",
        "# Predictions\n",
        "train2_pred = MLP.predict(data_df_train2)\n",
        "val_pred = MLP.predict(data_df_val)\n",
        "train_pred = MLP.predict(data_df_train)\n",
        "test_pred = MLP.predict(data_df_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewcFR2-4pidS",
        "colab_type": "code",
        "outputId": "e0ca0031-eb19-41ed-e4c0-e32f961a7516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Evaluate neural network using three-fold cross-validation\n",
        "score = cross_val_score(MLP, data_df_train, label_train, cv=10)\n",
        "mean_score = score.mean()\n",
        "\n",
        "print(f'The accuracy of the validation set in 10 different folds is {score}')\n",
        "print(f'\\n The mean accuracy of the validation set of 10 different folds is {mean_score}')\n",
        "\n",
        "# Evaluate accuracy of neural network on training set\n",
        "acc_train = accuracy_score(label_train2, train2_pred)\n",
        "print(f'\\n The accuracy of the training set is {acc_train}')\n",
        "\n",
        "# Evaluate accuracy of neural network on validation set\n",
        "acc_val = accuracy_score(label_val, val_pred)\n",
        "print(f'\\n The accuracy of the validation set is {acc_val}')\n",
        "\n",
        "# Evaluate accuracy of neural network on test set\n",
        "acc_test = accuracy_score(label_test, test_pred)\n",
        "print(f'\\n The accuracy of the test set is {acc_test}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the validation set in 10 different folds is [1.         0.84615385 0.84615385 0.76923077 0.84615385 0.92307692\n",
            " 0.76923077 0.92307692 0.76923077 0.92307692]\n",
            "\n",
            " The mean accuracy of the validation set of 10 different folds is 0.8615384615384615\n",
            "\n",
            " The accuracy of the training set is 1.0\n",
            "\n",
            " The accuracy of the validation set is 0.8571428571428571\n",
            "\n",
            " The accuracy of the test set is 0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozQ2zOjOFNVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "69b18c6e-9918-4396-bb07-3da96a534d81"
      },
      "source": [
        "# Confusion matrices and classification reports\n",
        "print('Confusion matrix and classification report of validation set')\n",
        "print(confusion_matrix(label_val, val_pred))\n",
        "print(classification_report(label_val, val_pred))\n",
        "\n",
        "print('Confusion matrix and classification report of training set')\n",
        "print(confusion_matrix(label_train2, train2_pred))\n",
        "print(classification_report(label_train2, train2_pred))\n",
        "\n",
        "print('Confusion matrix and classification report of test set')\n",
        "print(confusion_matrix(label_test, test_pred))\n",
        "print(classification_report(label_test, test_pred))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix and classification report of validation set\n",
            "[[8 0]\n",
            " [2 4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89         8\n",
            "           1       1.00      0.67      0.80         6\n",
            "\n",
            "    accuracy                           0.86        14\n",
            "   macro avg       0.90      0.83      0.84        14\n",
            "weighted avg       0.89      0.86      0.85        14\n",
            "\n",
            "Confusion matrix and classification report of training set\n",
            "[[86  0]\n",
            " [ 0 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        86\n",
            "           1       1.00      1.00      1.00        31\n",
            "\n",
            "    accuracy                           1.00       117\n",
            "   macro avg       1.00      1.00      1.00       117\n",
            "weighted avg       1.00      1.00      1.00       117\n",
            "\n",
            "Confusion matrix and classification report of test set\n",
            "[[8 0]\n",
            " [1 6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       1.00      0.86      0.92         7\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.94      0.93      0.93        15\n",
            "weighted avg       0.94      0.93      0.93        15\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC1QdnXa-t2c",
        "colab_type": "text"
      },
      "source": [
        "## Learning curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKQymgrz-zer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WEGLATEN BIJ SAMENVOEGEN IN BRAT_ASSIGNMENT\n",
        "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    axes.set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes.set_ylim(*ylim)\n",
        "    axes.set_xlabel(\"Training examples\")\n",
        "    axes.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores  = \\\n",
        "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes.grid()\n",
        "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_VlBm7C-tC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "0e123130-573c-41f1-caf8-028445c567f2"
      },
      "source": [
        "# Classifiers\n",
        "clsfs = [MLP]\n",
        "\n",
        "# Plot figuren\n",
        "fig = plt.figure(figsize=(24,8*len(clsfs)))\n",
        "  \n",
        "# Create a cross-validation object\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.15, random_state=0)\n",
        "# cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
        "# cv = StratifiedShuffleSplit(n_splits=10, test_size=0.15, random_state=0)\n",
        "\n",
        "# Now use the classifiers on all datasets\n",
        "num = 0\n",
        "for clf in clsfs:\n",
        "    # Split data in training and testing\n",
        "    # title = str(type(clf))\n",
        "    if hasattr(clf, 'n_estimators'):\n",
        "        title = f\"Random Forest Classifier, n(trees) = {clf.n_estimators}\"\n",
        "    elif hasattr(clf, 'C'):\n",
        "        title = f\"SVM Classifier, C (slack) = {clf.C}\"\n",
        "    elif hasattr(clf, 'n_neighbors'):\n",
        "        title = f\"kNN Classifier, #neighbors = {clf.n_neighbors}\"\n",
        "    elif hasattr(clf, 'hidden_layer_sizes'):\n",
        "        title = f\"Neural Network\"\n",
        "    ax = fig.add_subplot(len(clsfs), 3, num + 1)\n",
        "    plot_learning_curve(clf, title, data_df_train, label_train, ax, ylim=(0.3, 1.01), cv=cv)\n",
        "    num += 1\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAHwCAYAAAAy6LH2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzde3xcdZ3/8ddnLkkml6b3tE2atizl\nVgpFSspF2iq6wnphF0VBvODyswgCoossynrBFURdXVFZEf3h6k8WUZddWamLCqblWtoKCOVSoPSS\nlt7b3DPX7++PyUwnySRN25zMTM77+XjMo3POnMx85zSZ93yvx5xziIiI+EGg0AUQEREZLQo9ERHx\nDYWeiIj4hkJPRER8Q6EnIiK+odATERHfUOiJFCkz+7KZ/bzQ5ThSZjbbzJyZhQpdFhGFnkgvM9to\nZjvNrCpn3/8xs+YCFisvM1vaGyT/1m//o2Z26TCfw5nZ0Z4UUKRIKfRE+goCn/L6RUao1tMJfNjM\nZo/Ac3lCtTspNgo9kb6+CVxnZuPzPWhmx5nZH8xsr5m9bGbvz3ms2cz+T872pWb2aM62M7NPmtkr\nwCu9+24zsy1m1mZma83s7EMo637g34EvDXaAmf29mb1oZvvM7EEzm9W7f2XvIc+aWYeZfcDMVpjZ\ne3sfP6u3vO/s3T7HzJ7pvR8ws38ys029NeOfmVlt72OZpszLzGwz8HCeMr23t1Z94iG8V5ERodAT\n6WsN0Axc1/+B3mbPPwD/AUwFLgL+zcxOOITn/1tgEZD5mdXAAmBi7/P+yswqDuH5bgbea2bH5inv\n+cDngQuAKcAjwD0AzrnFvYed7Jyrds7dC6wAlvbuXwJsABbnbK/ovX9p7+0twFFANfD9fi+/BDge\neEe/Mn0M+DrwNufc84fwPkVGhEJPZKAvAleb2ZR++98FbHTO/cQ5l3DOPQ38J3DhITz315xze51z\n3QDOuZ875/b0Pt+3gHJgQIANxjm3HbgD+Eqehz/R+3ovOucSwC3AgkxtL48VpMMK0mH3tZzt3NC7\nBPi2c26Dc64D+BxwUb+mzC875zoz77PXtcBngaXOuVeH+x5FRpJCT6Sf3hrIb4Eb+j00C1hkZvsz\nN9IBMO0Qnn5L7oaZXdfb/Nja+3y1wORDLPLXgXeY2cl5yntbTln3AgbUD/I8TwDHmFkd6drnz4CZ\nZjYZaAIyTaIzgE05P7cJCAF1g73PXp8FbnfOtQz7nYmMMHUyi+T3JeDPwLdy9m0BVjjn3j7Iz3QC\nlTnb+cIwe1mT3v6764FzgHXOuZSZ7SMdTMPmnNtjZt8B/rnfQ1uAm51zdw/zebrMbC3pgTzPO+di\nZvY48BngNefc7t5Dt5EO1IxGIAHsABr6v88cfw38r5ltd87953DKJDLSVNMTyaO3+e1e4Jqc3b8l\nXRP6sJmFe2+nmdnxvY8/A1xgZpW9UwEuO8jL1JAOi11AyMy+CIw7zCJ/GziTdD9axh3A58xsHoCZ\n1ZpZblPsDtJ9crlWAFdxoCmzud82pPsFP21mc8ysmnSz6b29TahDWQecC9xuZu8Z7hsTGUkKPZHB\nfQXIztlzzrWTrq1cRLq2s51002J57yH/CsRIh8lPgYPVsB4E/hdYT7qJsIf8zYIH5ZxrA75BekBM\nZt9/9ZbvF2bWBjwPnJfzY18Gftrb/JkZhbqCdBivHGQb4C7g//Xue7233FcPs5zPku4b/ZGZnXew\n40VGmukisiIi4heq6YmIiG8o9ERExDcUeiIi4hsKPRER8Q2FnoiI+EbJTU6fPHmymz17dqGLccQ6\nOzupqqo6+IE+NWbPT2a0dO6oaecG3vofk6MzFqOqvPzADrMhjz9oWUaTDTLvvv/+fMcNZ58ZnV1d\nVFVWDjx2OOU43ONKyJj928qxdu3a3c65/ssIAiUYerNnz2bNmjWFLsYRa25uZunSpYUuRtEq6vPj\nHKRS+W+JxMBbMpl+bDCBQPrDNRDoexvkA7d53TqWzpvn0Zvz0GCB3//ffPv6/9wQjze//jpL58xJ\nb5uN3L+Z1+j//5JvH6T/D4ezL1/gD2ffcJ+/377m555j6cn9V6w7/OcbdN/hfHEJBKDiUNZbz8/M\nNg32mGehZ2Z3kZ6EutM5N+ASImZmwG3A3wBdwKXOuT97VR6RvLwOsFAIysrGZI3hkGXOgdfnIhCA\n6mpvX+Ng8tWij3Rf//3J5OE9XyoFbW0DjzuSsuXbd7j/z3Pnevo74mVN799JX27kZ4M8fh4wt/e2\nCPhB77/euvtuuPFG2LwZGhvh5pvhkks8f1lfKdQ5TqXSf2yZYMrcd04BJqNruLWcQjCDSKTQpciv\no8Pzl/As9JxzKw9yRefzgZ+59JIwT5rZeDOb7px7w6sycffdsGwZdHWltzdtSm+Dgm+kjOQ5TiQG\n1r6SyQOBFY8f2M48PlRTkwJMxPcK2adXT991Blt693kXejfeeODDOKOrCz7+cbjnHs9eNp/5e/bA\npEmj+pqj4uGHobu7776uLrjySnjjDRg/HmprYdy49L/V1elbOHwgzBIJiEbhtdcO9KlkZIIrN8DC\n4SH7wESkyN13H9x6K2zbBjNnwi23eFYRKYmBLGa2DFgGUFdXR3Nz82E9z5LNm/Nes8V1d9Oxfv3h\nF/AwBJ2jfc+eUX3N0VDd3Z3/HLe1YZ/97KA/lwqHidfUkKipIVFdzfGVlWyvrSVRU0O8uppEdXX2\nsdzj4tXVuLIy795QEero6aF53bpCF6No6fwMrdjOz9SHHuLY73yHYDSa3rF5M8nLLuPlF19k59ve\nNuKv5+mC073Nm78dZCDLD4Fm59w9vdsvk76i8pA1vYULF7rDHr05e3a6ua2/xkZ4/fXDe87D1Lxy\nJUsXLx7V1xwVc+ak+/L6a2iA3/0OduyA/fuhtTXdft/RAe3t6e3W1vRj+/fTvmMHNdFoel97+9Cv\nGYmka42ZWmTm38xt/PiB+yZMSNc2w2FvzoOHSnb05ijR+Rmap+cn00oTjUJPz4H7Q+27+eb0331/\ns2bBxo2HVQwzW+ucW5jvsULW9O4HrjKzX5AewNLqaX8epE9ubn8TQGVluiqdb8it1wrxml675Zb8\n5/jWW+HEE2HevHRfXDyebgbt7Ez/4mf64oJBKCtj7UsvHfjDTCTSo80yYZkTjtntzL7W1nToZrb7\nN2f3V1U1eGD239c/OINB786jFI/cprcZM+CGG+CCCwpdqoGcS/9dHSRkJr3yCmzYMLxAGs5jubd8\nI0oPV74vzyPAyykL9wBLgclm1kL6StRhAOfcHcBy0tMVXiU9ZeFjXpUlK9NGrNGb3jnYOTZLDyAp\nK0sHzuTJ6QEo8TjEYumQ6uxM78uM5AqH04EzcWL+1xxKLNY3MA8WnK+/fmB/T8/Qz11Tk78Gmbud\nr6Y5btzIfOEplQ/jUnbffXD99Qf6qbduTW/DwHPt3OCBEYsdecDke57+PzOMlrv5Qz0YCkF5+eC3\nior073Dm/mDH9N9XVjb48eefn+7v76+xcVj/RYeq5K6nd0TNm0WkqCdfF4Hm5maWLlqU/iPv7EyH\nYWZ0ZjCY/uMMh70dvJJpXh0sMAd7rLU1/bODMRsYioPVLvuHZnU1zS+8wNKXX+77YQzpZt5vfMPb\n4MtMA8lM98j3b//7Qz02nPuH+DMb3niDozJfpo709VesyP/lJxSCadMGhs+RKis7EBJDhchwHhvk\n+DUtLSw84YSBz1NWln5fo63/FwtItw7deedhV0iKtXlTZGiRyIH+Okg3c2a+6XZ0HAjCTLNoODyy\nf7Tl5TB1avp2KJxLf1D2D8J9+/I3x+7fn65BZO4nEoM/dzDIWVVV6S8C/ZuSurvhuuvg3nuPPGgG\nu18CX5KPyt3I/G4Eg+na9aHeH6y2n0jAGWcMDJ/hhNVQQTUKXR4dlZVw7LGev86wZb6kafSmSD+h\nUPpWWZluRsz0YcTj6QDs6koPesnU/jK1wdHue8tM/o1EYPr0Q/tZ59LvY4ja5c4NG6j/7W/z/3ym\nqSvzoZ15/4f7oX+w+/23hxMyI/2a/e6veOkllsyff6A8R6KpKf2FpL/6evjOd47sueWACy5I3zo6\nSnpFFhFv9e8fhPz9g5nBLGbpEMjM6ytGZun3UlWV/mDN45V166h/+unBP4x/8xuPC1nc3Eg2091w\nQ/5m5BtuGJnnl1Gn0JOxJRA40FRUU5Pel0ymQ7CQ/YMjTR/Go6N/05sGDHlnqCUBR5BCT8a+YHBg\n/2CmWbSnp28QetU/ONL0YTx6Mk1vMjz9lw7MLJadCbWhlgo82CWhRkAR/1WLeCjTzFlZmZ4Kkekf\njMUOzB8shv7BoejDWLySCancq5Dk3h/q8kqh0IEvjpl1bjO33Mtm9b+M1ii1tCj0RKBv/2B1NUyZ\ncqB/MBo9EITd3ek/8MwfczH3D4oMdumszs6B1zXsf127zAChTKtH/+DKd/3HEvhbUOiJDCa3f3Dc\nuPS+3P7Bjo50CCaTB/7gMx8QpdQ/KMWvf3Nh7r8w+MVtM6NaM1cVydyfOvXAyNfBal5jlEJP5FAM\n1T/Y3X1gxGju8cXePyijY6gmw4NdiDXTZJgJrdxb/8A6WJNhMHjgd9eH9JcocqRy+wcnTcrfP5h7\nccxi7B+U4cvXZAh9wytfzWuwJsNMU3m+psLMTUaMQk9kpA3WP5hpFs1MpO/fP6iL2o6szKjB3NpU\n7q3/MZntg/0fZIIr83+WO1gj02SYr/al/9uioNATGQ2BQHr5qYqKA/2DicSBgTKZQTJ+6h/sH0IH\nuw32HND3HGUWK+9fa8oNpaGaA3Pv978pvEqeQk+kUDK1g0gkvaC0cwfWF83MH8z0Dzp3oFl0NA1V\nU+pfW8o08w0VCrkhNVhTXm4zYO6/gwVR/6Datg2OOcbb8yIlS6EnUixyl0mrqsrfP9jRkQ6X9va+\n/UOQvzmv//7+Dtac1z+IhhqyPtzaUu5NZJQp9ESKWb7+wU2b0leVziyr1t2dv7bUv6Z0KLUlhZKM\nUQo9kVLUv39QRIZFY2FFRMQ3FHoiIuIbCj0REfENhZ6IiPiGQk9ERHxDoSciIr6h0BMREd9Q6ImI\niG8o9ERExDcUeiIi4hsKPRER8Q2tvSlSwpKpJNFklKAFCQfDBEzfY0WGotATKUFd8S7aetpoi7bh\nSF8yyDBCwRCVoUoi4QhlwTLCwTChgP7MRTL01yBSIqKJKO3RdqLJKFtatxAKhKgqq8JyLgGUTCXp\nSnTRFmvDOYdhBAIBKoIVRMIRKkIV2SBUrVD8SKEnUsTiyThd8S72dO8hnowTDAQJWICa8pq8xwcD\nQYKBYJ99zjniqTj7evaRcilwgEE4EKYyXEkkFKEsVEYoEFKtUMY8/YaLFJlkKkl3opu93XvpjncT\nsADloXIqQhWH9XxmRlmwjLJgWZ/9iVSCjlhHuonUOTAIWIBIKEJluDLbPBoOhPvUJkVKmUJPpAg4\n5+hJ9NDa05rtpysPlQ9aoxsJ+Wp2KZcilozRnegmlUpBb9aVB8upDFdmm0fDgfCAGqXIcKVcimQq\nSSKVIOmSxJIxookozjmm10z39EuWQk+kgDL9dK3RVhKpRN5+utGUqVXmcs6RdEnaom3s696XHTgT\nDoSJhCPZ5tFwIN1XqFqhOOdIuVQ21OLJOLFkjJ5ED/FknHgqjpn16XcOWpB4Ku552RR6IqMs00+3\nt3svsWSMYCBIRaiCiEUKXbS8zIyQ5a8V9iR66Ih1pPsKORCalaFKKsIVhANhTaUYo/rX1qKJaLbG\nFk/Fs1+OcOnfoYAFCAaClIXKqLD8TfXxmEJPZEzI9NPt795PZ7wTw6gIV1AT8q750muZgCvnQM3Q\nOUcilaA12sqe7j2AplKUqkwNPxNsiVSCaDKaDrUhamvBQJDKYGXR1vj1Wyfikdx+uvZYO845wsGw\np/10hWZm6T6/YLjP/sGmUvTvK9RUitE1WG2tJ9FDIpUg5VLp8MqprYUCoSFra8VOoScywqKJKB2x\nDvb37M/201WGi/eb72g43KkUmQBVrfDw5KutJVIJtrRuIZaMkUglDvxeOvrU1sqCZWPyd1a/SSIj\nIJFK0BnrZF/3PqLJKAELpPvpwsXZT1cMNJViZGQHjKSSQ9bWnHMELEDSJUm5FOWh8qLtR/aSQk/k\nMKVciu54N/u692X76byeZuAHRzqVYqwZqm8tmoz2OR84sgsYhAKhvLW1gAUGND/7iUJP5BBk+una\nY+209rSScinKgmUKOo/lm0oB6Vph/6kUsWSMbe3bqAxVlsxUitzaWiKVSI+C7A22fLW1TKhVhCrU\nB3qIFHoiwxBLxuiIdbCve5/66YpIvlqhmRFNROmMdRbNVIp8tbWeRE823FKpFA6XHTSSW1vLF/Zy\n+BR6IoNIpBJ0xdLz6dRPV1oONpUiEy6hYGhAX+HhDpo5WG0t0z8J6Wkcqq0VhkJPJIf66camoaZS\ndCe6aY+1p3f0jmDM7SsMBUKEg2EMI+mSfYJNtbXSo9AT31M/nX8dylQKwwbU1oKBIEELqrZWQhR6\n4luZfrr93fuJp+LqpxNg8KkUMjYo9MRXBuunqwiX5uoSInJoFHoy5mX66VqjrbRH2zEzyoPqpxPx\nI4WejEnOOaLJKG3Rtmw/XTgYprqsWs2XIj6m0JMxJZaMZZcDy/TTRcIRDTIQEUChJ2NAMpWkM9bJ\n/uh+uuPdBC1Ieahc/XQiMoBCT0qS+ulE5HAo9KRkqJ9ORI6Up6FnZucCtwFB4MfOuVv7PT4LuAuY\nAuwFPuSca/GyTFJ61E8nIiPFs9AzsyBwO/B2oAVYbWb3O+deyDnsX4CfOed+amZvBb4GfNirMklp\naetpy/bTaT6diIwEL78qNwGvOuc2OOdiwC+A8/sdcwLwcO/9P+V5XHwk5VJ0xbvY1r6NaCLK9s7t\npFyKmvIaqsqqBiwXJSJyqLxs3qwHtuRstwCL+h3zLHAB6SbQvwNqzGySc25P7kFmtgxYBlBXV0dz\nc7NXZR41HR0dY+J9jASHy171GZdeBirWHWPTs5sKXbSi1NPZw7rV6wpdjKKl8zO0Yj4/KZdiW3Cb\np69R6IEs1wHfN7NLgZXAViDZ/yDn3J3AnQALFy50S5cuHcUieqO5uZmx8D4OVzwZT1+frmcf8WSc\nYKDvor3rVq9j3mnzClzK4qRzMzSdn6EV8/npiHUwd+JcTwemeRl6W4GZOdsNvfuynHPbSNf0MLNq\n4L3Ouf0elkkKKJlK0hXvYl/Pvmw/XXmonIqQ+ulEZHR4GXqrgblmNod02F0EfDD3ADObDOx1zqWA\nz5EeySljiHOO7kQ3bT1ttEXbwNBle0SkYDwLPedcwsyuAh4kPWXhLufcOjP7CrDGOXc/sBT4mpk5\n0s2bn/SqPDK6Ui5Fa08re7v3kkglCAfDVJVVaT6diBSUp316zrnlwPJ++76Yc//XwK+9LIOMvs5Y\nJzs6dpBwCSrDlUQsUugiiYgAhR/IImNILBljV+cu2qPtRMIRKoLqqxOR4qLQkyOWTCXZ172PPd17\nCAVCjKsYV+giiYjkpdCTw+acoyPWwc7OnSRTSa2BKSJFT6EnhyWaiLKjcwfd8W4i4QiRsPrtRKT4\nKfTkkCRSCfZ272Vf9z7CwbCmHohISVHoybA452iLtrGzcyeGqSlTREqSQk8OqjvezY6OHUSTUSrD\nlVr4WURKlkJPBhVPxtndtZvWaCsVoQo1ZYpIyVPoyQCZ1VR2de4iEAgwrlxTEERkbFDoSR9d8S62\nt29Pr6ZSVqmrk4vImKLQE0CrqYiIPyj0fE6rqYiInyj0fEqrqYiIHyn0fCiaiLKzcydd8S6tpiIi\nvqLQ85FkKsme7j1aTUVEfEuh5wPOOdqj7ezo3KHVVETE1xR6Y5xWUxEROUChN0YlUgl2d+5mf3S/\nVlMREeml0BtjtJqKiMjgFHpjSFe8i+0d20mktJqKiEg+Cr0xYMBqKmVaTUVEJB+FXglLuRT7e/az\nu2s3QQtqNRURkYNQ+1cJykxBeH3f6+zu3E1VuEoTzEWkZN334n00/aiJ475/HLNvm83dz93t2Wup\npldiMqupdMY7qQxXKuxEpKTd9+J9XP+H6+lOdAOwuXUzy/5nGQCXzL9kxF9PNb0SkUwl2dW5i9f3\nv048FWdc+ThCAX1nEZHS1ZPo4aYVN2UDL6Mr3sWND93oyWvqU7PIZZoyd3buxOGoKavRaioiUpLa\nom2s2baGVVtXsaplFc/ueJZYMpb32M2tmz0pg0KviGk1FREpZbs6d7Fq6yqe2voUq7au4oVdL5By\nKUKBEPOnzufvF/w9v3rhV+zp3jPgZxtrGz0pk0KvCCVSCfZ0pReGLg+VazUVESl6zjm2tG3J1uJW\nbV3Fhn0bAKgIVfCm6W/i2kXX0tTQxKnTT6UyXAnAvKnz+vTpAVSGK7n5nJs9KadCr4gMWE1FUxBE\npEilXIr1e9b3CbntHdsBqC2v5bT60/jgiR+kqb6J+XXzKQuW5X2eC46/AIBbH72Vbe3bmFk7k1vO\nucWTQSyg0CsamdVU4sk4VWVVWk1FRIpKPBnnuZ3PZZsqn9r6FPt79gMwrWoaTQ1NLKpfxKL6RRw7\n+dhD+gy74PgLuOD4C+iIdTB34lxPxy0o9ApswGoq5VpNRUQKrzvezdo31mZDbu22tdkmyDnj53Du\nX52bDbpZtbNKZoCdQq+A9nbv1Woqctjue/G+bJPQjJoZ3PDmG7JNRSKHan/PflZvW51tqnxux3PE\nU3EM4/gpx3PxiRfT1NBE04wm6qrrCl3cw6bQG2XOOTpjnUST0fRqKmVVJfMNSYpH/wm9W9u3cv0f\nrgdQ8MmwbO/Ynm6mbEnX5F7a/RIORzgQ5uRpJ7Ps1GUsql/EwhkLqa2oLXRxR4xCbxTlrqZiGNXl\n1YUukpSorz36tQETersT3fzzyn/mvKPP00o90odzjtf3v85TW5/iwfUPsv4v69nYuhFIj5RcOGMh\n7zzmnSyqX8Qp004Z078/Cr1RkEwl2du9lz3deygLljGufJxqd3JInHO8uvdVVmxawQPPP8C29m15\nj9vZuZOjv3c0dVV1zBo/i1m1s5g1fhaza2en/x0/mwkVE/T7N8YlU0le2vNStqnyqa1PsbNzJwDj\nQuM4Y9YZfGTBR1hUv4h5U+YRDoYLXOLRo9DzkFZTkSOxt3svj2x+hJUbV7Ji0wre6HgDgIZIA1Xh\nKjrjnQN+ZmJkIh9/08fZtH8Tm1o38cjmR/jVC7/qc0xNWU02EGePn30gGMfPZnr1dC2CUIJiyRjP\n7niWp1qe4smtT7Jm2xraom0AzKiZwVkzz6KpvonTG04n+lqU+U3zC1ziwlHoeaQn0cOOjh30JHq0\nmooMSywZY+22tazYtIKVm1bylx1/weEYXz6eN896M0tmLWHxrMW0vtzKy9UvD5jQGwlFuGnpTQP6\n9Lrj3Wxp28LG/RvZ1LopHYj7N/Hi7hf5/Wu/J56KZ48tC5bRMK4hWzPMDcfG2kYqQhpdXAw6Y52s\nfWNttib39BtP05PsAeDoiUfz7mPenQ25hnENfX523YZ1hShy0VDojTCtpiLD5ZzjtX2vsXJTuib3\n+JbH6Yp3EbQgp844lX848x9YMmsJJ9ed3OdLUyutAyb0DjV6MxKOcMykYzhm0jEDHkumkrzR8UY6\nEHtrh5lwXL1tNe2x9j7HT6ue1icQs/drZzEhMmGEz5Bk7O3ey+qtq3ly65M81fIUz+18jqRLErAA\n86bM40Mnf4hF9Ytoqm9icuXkQhe3qCn0RkjKpWiLtrGzYyeBQICacjVlykD7uvfx2JbHskHX0tYC\nwOzxs7nwhAtZMmsJZ848c1hfljITeo9EMBCkYVwDDeMaeHPjm/s85pxjX8++bCBubD0QjM0bm9nR\nuaPP8ePLxw+oHWaaTqdVT9OCC4dga/vW7KjKVVtXsX7PegDKg+UsmLaAK0+7ktMbTufU6afqi/Uh\nUuiNgK54Fzs6dhBLxrSaivQRT8Z5evvTrNi4ghWbVvDsjmdJuRTjysfx5plv5qqmq1jcuJhZ42cV\nuqgDmBkTIxOZGJnIm6a/acDj3fHubHNpNhD3b+IvO/7C8leWk0glssdWBCuYWTszbyDOHDeT8lD5\naL61opKp8WeaKldtXZX9MlRdVs1pM07j7477O05vOJ2T6k5SE/MRUugdgXgyzq6u9GoqFaEKfeMS\nnHNs3L8x2y/32JbH6Ih1ELAAp0w7hU+f/mkWz1rMgmkLSv56iJFwhOMmH8dxk48b8FgilWBr29YD\nzaU5TaeZZtwMw5hRM6Nvc2nO/XHlY2vhhmQqyQu7Xsg2Va7auip7lYFJkUksaljEx9/0cRbVL+KE\nKSdoPMAIK+2/ugJJuRT7e/azq3MXoUBIYedzrT2tPLblsWzQZa4DNnPcTP72uL9lyawlnDXzrDE1\nwfdgQoFQNrwWz1rc5zHnHLu7dvepHWbu/37D79ndtbvP8RMqJvSpGeYGYl1VXdF3I/Qkenh2+7PZ\nkFvzxho6Yh1A+nfkLXPeku2P+6sJf1X076fUKfQOUWeskx0dO0i6pJoyfSqRSvDM9mey/XJPv/E0\nSZekuqyas2aexeWnXs6SWUuYPX62PsDyMDOmVE1hStUUTptx2oDHO2IdfUaZZgLxz9v/zP3r7yfl\nUtljK0IVB8Kwt9nU9hmV+yppGNdQkPln7dH2AxdK3bqKZ7Y/k71Q6rGTjs02VTbVNzGjZsaol8/v\nFHrDlLuaSmW4koqA2tX9ZHPr5nRNbuNKHt3yKG3RNgIW4OS6k7m66WqWzF7CKdNO8dUkX69Ul1Uz\nb8o85k2ZN+CxeDJOS1tLn1Gmm/an76/ctJKeRHrYPs9D0ILUj6sfMEE/c7+qrGpY5TnYGqe7u3b3\nmQS+btc6Ui5F0IKcVHcSH1vwMRbVL+K0+tOYGJk4IudIDp9C7yCSqST7uvexu3t3djUVGfvao+08\nvuVxVmxKD0DZuH8jAPU19bz7mHezeNZizpp5lobpj7JwMMycCXOYM2HOgMecc+zo3EHzk83YdMvW\nFDe1buKB9Q+wr2dfn+MnV04eNBAnV07GzPKucfrZ33+WVVtXkUqlWLV1Fa/tew1ID9Z504w38alF\nn6KpPn2h1OEGq4wehd4gtFOhli0AACAASURBVJqKvyRTSf6y4y80b2pm5aaVrN22lqRLUhmu5MyZ\nZ3LZKZexZPYSjhp/lH4PipSZMa16GvNr5zNv3sBaYlu0bcBI042tG1nVsor/evG/cLjssVXhKhpr\nG3l9/+sHao+9epI9/PwvP6e2vJaFMxZy0YkX0VTfxEl1Jw16oVQpHgq9PDKrqXTHu6kqq9LoqTGq\npa0l2y/36KZH2R/dj2GcVHcSV552JUtmLeHUGafqg2yMGFc+jvl185lfN3AJrmgiypa2LQMm6L+4\n+8W8z2UYz1/5vPr0S5BCL0f/1VR0jbuxpTPWyeMtj2fXssw0S02vns65R5/L4tmLObvxbPW7+FB5\nqJyjJx7N0ROP7rO/6UdNbG3fOuD4GTUzFHglSqFHuimzLdrGzs6dGKbVVMaIlEvx3I7nslMJ1mxb\nQzwVJxKKcMbMM/jIyR9hyawlHD3xaP1/S143vPmGvGuc3vDmGwpYKjkSvg89raYytmxr35Ztsnxk\n0yPZwQvzp87n8lMvZ/GsxSycsdDXK4DI8B3KGqdSGnwbevFknN1du2mNtmo1lRLWFe/iyZYn06Ms\nN67glb2vAFBXVcfbjnobS2Yt4exZZ2sRXjlsI7HGqRQP34be5rbN4NAUhBKTcile2PVCdi3L1dtW\nE0vGqAhWcHrD6Vw8/2KWzFrCsZOOVZOliAzgaeiZ2bnAbUAQ+LFz7tZ+jzcCPwXG9x5zg3NuuZdl\ngnQfXiKZUO2uRGzv2M7KTSuzt8w6hSdMOYHLTrmMxbMW01TfpIV4ReSgPAs9MwsCtwNvB1qA1WZ2\nv3PuhZzD/gn4pXPuB2Z2ArAcmO1VmaQ0dMe7WbNvDb9e8WtWblzJS3teAmBK5RSWzl6abbKcWjW1\nwCUVkVLjZU2vCXjVObcBwMx+AZwP5IaeAzLti7XANg/LI0XKOceLu1/MDkBZ1bKKaDJKebCcpvom\nLpx3IYtnLeb4yceryVJEjoiXoVcPbMnZbgEW9Tvmy8DvzexqoAp4m4flkSKys3Mnj2x6JD3KcvMj\n7OzcCcBxk47jows+yuzobN7/lvcTCUcKXFIRGUsKPZDlYuDfnXPfMrMzgP9nZic6l7OMOmBmy4Bl\nAHV1dTQ3Nx/xC0cTUQKBwk1P6OnsYd3qdQV7fS89tPMhfrLxJ+yK7mJK+RQ+NvtjnD35bJ5vfZ61\n+9eydt9aNnRuAKA2XMubxr+Jj9R/hFPHn8qk8kkA9LgeNjyzoZBvo2iN5d+dkaDzM7RiPj8pl2Jb\n0NsGP3POHfyow3nidIh92Tn3jt7tzwE4576Wc8w64Fzn3Jbe7Q3A6c65nYM978KFC92aNWuOqGzO\nOdbvWV/QgSzrVq9j3mkD1wcsdf0X6AUIWIAAARIuQVmwjNNmnMaSWUtYMnsJJ0w5Ie/cyLF6fkaC\nzs3QdH6GVsznpyPWwdyJc4+4G8PM1jrnFuZ7zMua3mpgrpnNAbYCFwEf7HfMZuAc4N/N7HigAtjl\nYZnEY7c+emufwIP0t7dIOMJP3vUTTm84ncpwZYFKJyJ+51noOecSZnYV8CDp6Qh3OefWmdlXgDXO\nufuBfwB+ZGafJj2o5VLnVdVTRsW29vxNE13xLt46562jXBoRkb487dPrnXO3vN++L+bcfwE4y8sy\nyOh5YP0Dgz6mK0SLSDHQQpNyxKKJKF94+Ass++0yGsc1UhHsO0lcC/SKSLFQ6MkR2dy6mb+79++4\n65m7WHbqMpo/1sw3//qb1NfUYxj1NfV84+3f0NqFIlIUCj1lQUrY7175HZ/5/WcwjLvecxfvOPod\ngBboFZHipdCTQxZLxrj5kZv58Z9/zIK6BfzgXT+gsbax0MUSETkohZ4cki2tW7jigSt4evvTXHbK\nZfzT4n+iLFhW6GKJiAyLQk+G7cFXH+TTD34ah+PH7/4x5809r9BFEhE5JAo9Oah4Ms4tj97CnWvv\n5KS6k7jjnXcwa/ysQhdLROSQKfRkSFvbtvKJBz7Bn9/4Mx9b8DG+sPgLlIfKC10sEZHDotCTQf1h\nwx+49nfXknRJfviuH/KuY95V6CKJiBwRhZ4MEE/G+fpjX+cHa37AiVNP5I533sGcCXMKXSwRkSOm\n0JM+trZv5coHrmTNtjV85OSP8KUlX6IiVHHwHxQRKQEKPcl6aMNDfOp/P0U8Feff3vlvnH/s+YUu\nkojIiFLoCYlUgm889g1uX307J0w5gR++64ccNeGoQhdLRGTEKfR87o32N7hy+ZU8tfUpPnTSh7hp\n6U1qzhSRMUuh52PNG5u5+ndXE01Euf1vbudvj/vbQhdJRMRTCj0fSqQS/Mvj/8L3nvoex08+njve\ndQdHTzy60MUSEfGcQs9ntnds56rlV/FEyxN88MQP8pW3fIVIOFLoYomIjAqFno+s3LSSq5ZfRVe8\ni++e+13ee8J7C10kEZFRpdDzgWQqybef+Da3rbqNYyYdww/f9UPmTppb6GKJiGQ550bldRR6Y9yO\njh18cvkneaLlCT4w7wPc/Nab1ZwpIkUjmogSS8YwjNqKWszM09dT6I1hj2x+hKuXX017rJ1/fce/\n8v557y90kUREiCVjxJIxnHNUhauYUjWFSChCMBD0/LUVemNQMpXktlW38e0nvs3cSXO59333cuzk\nYwtdLBHxsXgyTjQRxeGIhCNMq5pGZVklocDoxpBCb4zZ1bmLq353FY9ufpT3nfA+vnbO16gMVxa6\nWCLiQ4lUgmgiSsqlKA+WU1ddR2W4knAwXLAyKfTGkMe3PM4nl3+Stmgb3/7rb/OBEz9Q6CKJiM8k\nU0l6Ej2kXIqyYBlTKqdQWVZJWbCs0EUDFHpjQjKV5HtPfY9vPfEtjppwFPe89x6Om3xcoYslIj6R\ncil6Ej0kU0nCgTCTKidRFa4qygtOK/RK3O6u3Vz9u6tZuWklFxx3Abe+7VaqyqoKXSwRGeNSLkU0\nESWRShAKhBhfPp7q8mrKg+Wej8A8Egq9EvbElif45PJP0trTyjff/k0uPvHiov5lE5HS5pyjJ9FD\nIpUgYAFqK2qpKauhIlRRMp89Cr0SlHIpvv/U9/nm499k9vjZ/PyCn3PClBMKXSwRGYOcc0STUeLJ\nOGbGuLJx1FbUllTQ5VLolZg9XXu45nfX0LypmfOPPZ9vvP0bVJdVF7pYIjKGOOeIJWPEk3EAaspr\nqKuqIxKOELBAgUt3ZBR6JeSprU9xxQNXsK97H7e+7VY+NP9DJflNS0SKU+6k8eqyaqZWTaUiVDEq\nk8ZHi0KvBKRcih+s/gFff+zrzKydyf0X38+JU08sdLFEZAzInTReGa5kevV0KsOVYyrocin0itze\n7r186n8/xcOvP8y7j3k333z7N6kpryl0sUSkhOVOGq8IVTCtujCroxTC2H+HJWz11tVc8cAV7One\nwy3n3MJHTvqImjNF5LBkJ42nUiRTSaZWTS346iiFoNArQimX4odrfsjXHv0aDeMauP+i+5lfN7/Q\nxRKREpNMJYkmo9lJ45MrJ9MSamHOhDmFLlrBKPSKzL7ufVz74LX8ccMf+Zu5f8O3/vpbjCsfV+hi\niUiJ6D9pfELFBKrLqikLlmFmGP5uLVLoFZG129ZyxQNXsLNzJ199y1e5dMGlas4UkYPqP2l8fMV4\nasprin51lEJQ6BUB5xx3/vlObnnkFmbUzOA3F/2Gk6edXOhiiUgRy0waT6QS2QuwltrqKIWg0Cuw\n/T37+cyDn+HB1x7kvKPP41t//S1qK2oLXSwRKUK5k8bNjOqy6uzqKKU+aXy0KPQK6Ok3nuYTD3yC\nHR07uGnpTVx2ymX6hiYiA2QmjeOgunxsThofLQq9AnDOcd/W+/i/j/1f6qrr+K8P/BenTD+l0MUS\nkSKSmTSOQWWoksk1k4mEIgq6I6TQG2WtPa38w+//gd9t+B3v+Kt38O13fJvxFeMLXSwRKQKZSePO\nOSrC/po0Plp0JkfRs9uf5RMPfIJt7dtYNmcZX3zPF9WcKYfNOUfSJbMDGYKBIAELqG+nxOSujlIe\nLPftpPHRotAbBc45fvLMT/jKiq8wtWoq973/Piq2aoSVDF/KpYgn4yRSCVKpFB2xDgDKg+VUhatI\nuVS23yeRSuBw2d8v5xyGYWbZUAxYIBuSMvoyq6M45wgFQ0yunExVWRVlwbJCF23MU+h5rC3axnW/\nv44HXnmAtx31Nr7zju8wITKBdVvXFbpoUqQSqQTxZJxkKpneYRC0IBWhCsZXjGdLcAuzx88mHAjn\n/eLknCPlUtlb0iXT/6aS2VBMpBLEEun7wICQzASjmRG0YJ9tOTwpl6In0ZNdHWViZCLVZdWUh8oL\nXTRfUeh56Lkdz/GJ336CLW1b+Kez/4nLF16ub9aSlXKpbAClUqls8JQHy6kpryESihAOhgkHwn0G\nLwQsMGSNIBNUQYY34CETiLkhmUylm01zQzKRSuCcy3mhA3eDFszWJDMhqYDsO2k8GAgyvnw81eXV\nmjReQAo9Dzjn+OmzP+WmFTcxKTKJ//zAf3LajNMKXSwpoEztLeVS6eCwdHhFQhFqy2spC5ZlA260\nPwwDFiAQHN6XsWww5oRkbijGk3HiqXi2dklvRubWJHObWDMhOZYCoP/qKJo0XlwUeiOsPdrOZ//w\nWf5n/f/w1tlv5bbzbmNiZGKhiyWjJDcEkqlkep1Dg7JAGdVl1URCEcpCZYQCoZIckZcJquGUvU8T\na05IxlPxbP9kPBkn5mLpgIRsSALZLwb9B+kUY2tJZnWUeDJOwALUlNUwrmKcJo0XodL7qytiz+98\nnst/ezlbWrfw+Td/nitOu0K/8GNYbrg553A4goEgkVCEceXjKA+WEw6GCQVCvvw96BNQB2lpzYxE\n7R+SiVSiT0hGk1GSLtnn5zILKGeaV51z2VqW1+c9mogSS8YwjOryauqq6oiEI778/y4VCr0R4Jzj\n58/9nC/96UtMiEzg1+//NU31TYUulowQ5xzxVO/IyUyTnUE4EKYqXHWg76034OTQmRkhG965ywzU\nyQ3J3NGtZpZdrmu4I1kzo1mHI7s6CulJ41OqpmjSeAnRX+gR6oh18I9/+Ef+++X/ZumspXz3vO8y\nqXJSoYslhymZSmYDLjNoIxgIUhGsoKYi3S/j59pbMTjYQJ1wIMys8bOA4Y9kjSfjdMe70z8zyEjW\nZCqJwxEJR5hWpUnjpUr/Y0fghV0vcPlvL2fj/o3841n/yFVNV+mDsETkq705HGXBMqrCVVSEKrKD\nS/TBVrpGciRrKBDSpPExQH/Nh8E5xz3P38MXHv4CtRW1/PJ9v+SMmWcUulgyiP61N8MIBALpqQG9\ntbdQIEQ4GNaXFp87lJGsUpo8DT0zOxe4jXQ39o+dc7f2e/xfgbf0blYCU51zRb0QZWeskxseuoH7\nXryPxbMW873zvsfkysmFLpZAdgBDIpUg6ZLZgAsHw1SGKomEI6q9ificZ3/5ZhYEbgfeDrQAq83s\nfufcC5ljnHOfzjn+aqCoLzXw4q4Xufy3l/P6/te57szruKbpGnVeF0im9pbpZ8Glm7Iyq5aUh8oJ\nB8KqvYlIH15+3W0CXnXObQAws18A5wMvDHL8xcCXPCzPYXPOce+6e7nx4RupKavhF+/9BWc1nlXo\nYvlCbu0tMzIPB6FgiEgoQmW4krLggXlvmvwrIkPxMvTqgS052y3AonwHmtksYA7wsIflOSxd8S4+\n99Dn+PULv+asmWfx/b/5PlOrpha6WGNSZsBAZnBJe7SdgAWoCFVQW15LRbhCtTcROSLF0rFxEfBr\n53JmneYws2XAMoC6ujqam5uP+AWjiSiBwNAfnBs7N/LVF7/Klu4tfLjxw3yw8YPsemEXu9h1xK/f\n09nDutX+XXQ6M5k7M+ct0zyZmT8V64qx7flt2YnHckBHR8eI/A2MVTo/Q/P7+fEy9LYCM3O2G3r3\n5XMR8MnBnsg5dydwJ8DChQvd0qVLj6hgzjnW71lPTXnNoMf8ct0v+fwTn6eqrIp73ncPZzeefUSv\n2d+61euYd9q8EX3OYtTnkji9S00FLEB5qJxIKEIkHCEcSA8sye0fbW5u5kj/n8cqnZuh6fwMze/n\nx8vQWw3MNbM5pMPuIuCD/Q8ys+OACcATHpZl2Lrj3dz48I3cu+5ezmg4g9v/5nbqqusKXayS45yj\nPdpOWbCMSDiSXXMyE3DqexORQvAs9JxzCTO7CniQ9JSFu5xz68zsK8Aa59z9vYdeBPzC9blmSWG8\nsucVLv/t5azfs55rF13LZ874jEZnHoaUS9ER7WBK1RQmRiYq4ESkaHjap+ecWw4s77fvi/22v+xl\nGYbr1y/8mhv+eAOV4UruvuBulsxeUugilaRkKklnvJO66jomRCYUujgiIn0Uy0CWgumOd/OFP32B\ne56/h9PrT+f2d97OtOpphS5WSUqkEnTFu6ivqR+yv1REpFB8F3p3P3c3n3/o82xp3cLUqqkELci2\njm1c3XQ11515nVbqOEzxZJxoMkpjbSOV4cpCF0dEJC9ffcLf/dzdLPufZXTFuwDY0bkDgCsWXsEN\nb76hkEUrabFkjHgyTmNtIxWhikIXR0RkUL6a4XvjQzdmAy/X/S/fn+doGY6eRA/JVFKBJyIlwVc1\nvc2tm/Pu39a+bZRLMjZ0x7sxMxprG3W5FREpCb6q6TXWNubdP6NmxiiXpPR1xboIBUIKPBEpKb4K\nvZvPuXnAIItIKKL+vEPUEe2gIlxBw7gGDfwRkZLiq9C7ZP4l3PnuO2msbcQw6mvq+cbbv8EFx19Q\n6KKVhMwqKzXlNcyomaGJ+yJScnz3Nf2S+ZfwwRM/eNC1N6WvTOBNiExgatVUrbIiIiXJd6Enh07L\nionIWKHQkyFpWTERGUuG3adnZhEzO9bLwkhxSaQSdMY7qa+pV+CJyJgwrNAzs3cDzwD/27u9wMw0\no3sMiyfj9CR6aKxtVN+niIwZw63pfRloAvYDOOeeAeZ4VCYpsFgyRiwZ0zqaIjLmDLdPL+6ca+03\ngKHg17+TkdeT6ME5R2NtI+Wh8kIXR0RkRA039NaZ2QeBoJnNBa4BHveuWFIIWlZMRMa64TZvXg3M\nA6LAfwCtwLVeFUpGn5YVExE/OGhNz8yCwAPOubcAN3pfJBltnbFOIuEI06una5UVERnTDlrTc84l\ngZSZ1Y5CeWQUZVZZqS6r1rJiIuILw+3T6wCeM7M/AJ2Znc65azwplXhOy4qJiB8NN/Tu673JGKBl\nxUTEr4YVes65n5pZGXBM766XnXNx74olXtGyYiLiZ8MKPTNbCvwU2AgYMNPMPuqcW+ld0WSkJVIJ\nuuJd1NfUa5UVEfGl4TZvfgv4a+fcywBmdgxwD3CqVwWTkRVPxokmo1plRUR8bbihF84EHoBzbr2Z\naTJXiYgmoiRSCRprG6kIVRS6OCIiBTPc0FtjZj8Gft67fQmwxpsiyUjSsmIiIgcMN/SuAD5Jevkx\ngEeAf/OkRDJiuuPdBCzAzNqZWmVFRIThh14IuM05923IrtKiakMR64p1EQ6GqR9XTyigawWLiMDw\n1958CIjkbEeAP458cWQkdMY6qQhX0DCuQYEnIpJjuJ+IFc65jsyGc67DzDQEsMg45+iIdTCufBx1\n1XUEbLjfaURE/GG4n4qdZvamzIaZLQS6vSmSHI7cZcWmVU9T4ImI5DHcmt61wK/MbFvv9nTgA94U\nSQ6VlhUTERmeIasDZnaamU1zzq0GjgPuBeLA/wKvj0L55CCSqSQdsQ7qquuYVDlJgSciMoSDtYH9\nEIj13j8D+DxwO7APuNPDcskwJFIJOuOd1NfUax1NEZFhOFjzZtA5t7f3/geAO51z/wn8p5k9423R\nZChaVkxE5NAdrKYXNLNMMJ4DPJzzmMbCF0g0ESWWjCnwREQO0cGC6x5ghZntJj1a8xEAMzsaaPW4\nbJKHlhUTETl8Q4aec+5mM3uI9GjN3zvnXO9DAeBqrwsnfWlZMRGRI3PQJkrn3JN59q33pjgyGC0r\nJiJy5PTpWQI6Y51EwhGmV08nGAgWujgiIiVLoVfEtKyYiMjIUugVqcyyYhMrJzKlcoomnYuIjACF\nXhHSsmIiIt5Q6BWZZCpJZ7yTuuo6rbIiIjLCFHpFJJFK0BXvor6mnprymkIXR0RkzFHoFQktKyYi\n4j2FXhGIJqIkUgkaaxupCFUUujgiImOWQq/AtKyYiMjoUegVUHe8GzOjsbZRy4qJiIwChV6BpFyK\nUCCkZcVEREaRPm0LoDPWScACNIxr0LJiIiKjSOtajaLMKivVZdWEA2EFnojIKPM09MzsXDN72cxe\nNbMbBjnm/Wb2gpmtM7P/8LI8hZQJvAmRCUyrnlbo4oiI+JJnzZtmFgRuB94OtACrzex+59wLOcfM\nBT4HnOWc22dmU70qTyFpWTERkeLgZU2vCXjVObfBORcDfgGc3++YjwO3O+f2ATjndnpYnoJIppJ0\nxDqoq65jUuUkBZ6ISAF5GXr1wJac7ZbefbmOAY4xs8fM7EkzO9fD8oy6RCpBZ7yT+pp6raMpIlIE\nCj16MwTMBZYCDcBKM5vvnNufe5CZLQOWAdTV1dHc3HzELxxNRAkEvMt85xwORzgQZrttH/B4R0fH\niLyPsUrnZ3A6N0PT+Rma38+Pl6G3FZiZs93Quy9XC7DKORcHXjez9aRDcHXuQc65O4E7ARYuXOiW\nLl16RAVzzrF+z3rPFnXOLCs2s3bmoMuKNTc3c6TvYyzT+Rmczs3QdH6G5vfz42Xz5mpgrpnNMbMy\n4CLg/n7H/DfpWh5mNpl0c+cGD8vkuZ5EDymX0jqaIiJFyLPQc84lgKuAB4EXgV8659aZ2VfM7D29\nhz0I7DGzF4A/AZ91zu3xqkxe6453A2gdTRGRIuVpn55zbjmwvN++L+bcd8Bnem8lrSvWRTgY1rJi\nIiJFTJ/OI6Az1kkkHGF69XStsiIiUsQUekfAOUd7rJ3a8lrqqusImFZ1ExEpZgq9w5RZVmxi5USm\nVE7RpHMRkRKg0DsMWlZMRKQ0KfQOUWZZsek10xlfMb7QxRERkUOg0DsEiVSCrngXDeMaPJvYLiIi\n3lHoDVM8GSeajNJY20hluLLQxRERkcOg0BuGzLJiWmVFRKS0KfQOoifRg3NOq6yIiIwBCr0hdMe7\nMTMaaxsJB8OFLo6IiBwhhd4gtKyYiMjYo0/zPLSsmIjI2KTQy6FlxURExjaFXi8tKyYiMvYp9NCy\nYiIifuH70NOyYiIi/uHr0NOyYiIi/uLr0OtJ9GhZMRERH/Fl6JkZVWVVTK6crGXFRER8xJehB9Aw\nrqHQRRARkVGmiWgiIuIbCj0REfENhZ6IiPiGQk9ERHxDoSciIr6h0BMREd9Q6ImIiG8o9ERExDcU\neiIi4hsKPRER8Q2FnoiI+IZCT0REfEOhJyIivqHQExER31DoiYiIbyj0RETENxR6IiLiGwo9ERHx\nDYWeiIj4hkJPRER8Q6EnIiK+odATERHfUOiJiIhvKPRERMQ3FHoiIuIbCj0REfENhZ6IiPiGQk9E\nRHxDoSciIr6h0BMREd9Q6ImIiG8o9ERExDcUeiIi4huehp6ZnWtmL5vZq2Z2Q57HLzWzXWb2TO/t\n/3hZHhER8beQV09sZkHgduDtQAuw2szud8690O/Qe51zV3lVDhERkQwva3pNwKvOuQ3OuRjwC+B8\nD19PRERkSJ7V9IB6YEvOdguwKM9x7zWzxcB64NPOuS39DzCzZcAygLq6Opqbm0e+tKOso6NjTLwP\nr+j8DE7nZmg6P0Pz+/nxMvSG43+Ae5xzUTO7HPgp8Nb+Bznn7gTuBFi4cKFbunTpqBbSC83NzYyF\n9+EVnZ/B6dwMTednaH4/P142b24FZuZsN/Tuy3LO7XHORXs3fwyc6mF5RETE57wMvdXAXDObY2Zl\nwEXA/bkHmNn0nM33AC96WB4REfE5z5o3nXMJM7sKeBAIAnc559aZ2VeANc65+4FrzOw9QALYC1zq\nVXlEREQ87dNzzi0Hlvfb98Wc+58DPudlGURERDK0IouIiPiGQk9ERHxDoSciIr6h0BMREd9Q6ImI\niG8o9ERExDcUeiIi4hsKPRER8Q2FnoiI+IZCT0REfEOhJyIivqHQExER31DoiYiIbyj0RETENxR6\nIiLiGwo9ERHxDYWeiIj4hkJPRER8Q6EnIiK+odATERHfUOiJiIhvKPRERMQ3FHoiIuIbCj0REfEN\nhZ6IiPiGQk9ERHxDoSciIr6h0BMREd9Q6ImIiG8o9ERExDcUeiIi4hsKPRER8Q2FnoiI+IZCT0RE\nfEOhJyIivqHQExER31DoiYiIbyj0RETENxR6IiLiGwo9ERHxDYWeiIj4hkJPRER8Q6EnIiK+odAT\nERHfUOiJiIhvKPRERMQ3FHoiIuIbCj0REfENhZ6IiPiGQk9ERHxDoSciIr6h0BMREd/wNPTM7Fwz\ne9nMXjWzG4Y47r1m5sxsoZflERERf/Ms9MwsCNwOnAecAFxsZifkOa4G+BSwyquyiIiIgLc1vSbg\nVefcBudcDPgFcH6e4/4Z+DrQ42FZREREPA29emBLznZL774sM3sTMNM594CH5RAREQEgVKgXNrMA\n8G3g0mEcuwxYBlBXV0dzc7OnZRsNHR0dY+J9eEXnZ3A6N0PT+Rma38+Pl6G3FZiZs93Quy+jBjgR\naDYzgGnA/Wb2Hufcmtwncs7dCdwJsHDhQrd06VIPiz06mpubGQvvwys6P4PTuRmazs/Q/H5+vGze\nXA3MNbM5ZlYGXATcn3nQOdfqnJvsnJvtnJsNPAkMCDwREZGR4lnoOecSwFXAg8CLwC+dc+vM7Ctm\n9h6vXldERGQwnvbpOeeWA8v77fviIMcu9bIsIiIiWpFFRER8Q6EnIiK+odATERHfUOiJiIhvKPRE\nRMQ3FHoiIuIbCj0REfENhZ6IiPiGQk9ERHxDoSciIr6h0BMREd9Q6ImIiG8o9ERExDcUeiIi4hsK\nPRER8Q2FnoiI+IZCxBjYxwAAFUhJREFUT0REfEOhJyIivhEqdAFGQjwep6WlhZ6enkIXZdhqa2t5\n8cUXC12MojXa56eiooKGhgbC4fCovaaIjL4xEXotLS3U1NQwe/ZszKzQxRmW9vZ2ampqCl2MojWa\n58c5x549e2hpaWHOnDmj8poiUhhjonmzp6eHSZMmlUzgSXExMyZNmlRSLQUicnjGROgBCjw5Ivr9\nEfGHMRN6hbRnzx4WLFjAggULmDZtGvX19dntWCw25M+uWbOGa6655qCvceaZZ45UcUVEfGtM9Okd\nsrvvhhtvhM2bobERbr4ZLrnksJ9u0qRJPPPMMwB8+ctfprq6muuuuy77eCKRIBTKf6oXLlzIwoUL\nD/oajz/++GGXz0tDvTcRkWLjv5re3XfDsmWwaRM4l/532bL0/hF06aWX8olPfIJFixZx/fXX89RT\nT3HGGWdwyimncOaZZ/LKK68A0NzczLve9S4gHZh///d/z9KlSznqqKP47ne/m32+6urq7PFLly7l\nfe97H8cddxyXXHIJzjkAli9fznHHHcepp57KNddck33eXOvWraOpqYkFCxZw0kknZcvxs5/9jJNO\nOomTTz6ZD3/4wwBs3LiRt771rZx00kmcc845bN68Oe97e+211zj33HM59dRTOfvss3nppZdG9FyK\niIyUsfcV/dprobfWldeTT0I02ndfVxdcdhn86Ef5f2bBAvjOdw65KC0tLTz++OMEg0Ha2tp45JFH\nCIVC/PGPf+Smm27iN7/5zYCfeemll/jTn/5Ee3s7xx57LFdcccWAYfRPP/0069atY8aMGZx11lk8\n9thjLFy4kMsvv5yVK1cyZ84cLr744rxluuOOO/jUpz7FJZdcQiwWI5lMsm7dOr761a/y+OOPM3ny\nZPbu3QvA1VdfzUc/+lE++tGPctddd3HNNdfw3//93wPe2znnnMMdd9zB3LlzWbVqFVdeeSUPP/zw\nIZ8vERGvjb3QO5j+gXew/UfgwgsvJBgMAtDa2spHP/pRXnnlFcyM6CCv9853vpPy8nLKy8uZOnUq\nO3bsoKGhoc8xTU1N2X0LFixg48aNVFdXc9RRR2WH3F988cXceeedA57/jDPO4Oabb6alpYULLriA\nuXPn8vDDD3PhhRcyefJkACZOnAjAE088wX333QfAhz/8Ya6//voB762jo4PHH3+cCy+8MPvYYO9N\n5P+3d+/RVdVXAse/m0gJ0UCsjPhImwCTUcjjJuGRCAYwskiLFcyacSLCorBUYMBaYURhpOOjVRSx\nEZWqEeXVKA8rVIVRaSVLYgcGEgPERyOmwRILQhwij4FCsuePc3K9XG4CBpIbcvZnLRb3nPu79+77\n45dsfufx28aEW/tLeqebkcXHO4c0g8XFQVHROQ3lwgsv9D/+xS9+wXXXXcfq1aupqqpiyJAhIV/T\nqVMn/+OIiAhOnDjRrDaNufXWW8nIyGDt2rWMGDGCF1544YxfG6jhu9XX1xMTE+M/p2mMMW2Z987p\nPfIIREWdvC8qytnfgmpra7nyyisBWLx48Tl//6uuuorKykqqqqoAWLFiRch2lZWV9OzZk7vuuotR\no0axfft2srOzWbVqFTU1NQD+w5sDBw5k+fLlABQWFpKVlXXK+3Xp0oUePXqwatUqwLnRe9u2bef6\n6xljzDnhvaQ3ZgwUFDgzOxHn74KCs7p680zce++9zJo1i7S0tO80MztTnTt35je/+Y3/gpLo6Gi6\ndu16SruVK1eSlJREamoq5eXljBs3jsTERO6//36GDBmCz+dj+vTpADzzzDMsWrSIlJQUli1bxvz5\n80N+dmFhIS+99BI+n4/ExMSQ5yqNMaYtkIYr/84X/fr1061bt56075NPPqF3795hiqh5WmKZrUOH\nDnHRRRehqkydOpWEhASmTZt2Tj+jtYRjmbbzZRw1XMFrQrP+aZoX+kdESlQ15L1g3pvptWMvvvgi\nqampJCYmUltby6RJk8IdkjHGtCnt70IWD5s2bdp5O7MzxpjWYDM9Y4wxnmFJzxhjjGdY0jPGGOMZ\nlvSMMcZ4hiW9c2TPnj3ccsst9OrVi759+zJixAgqKirCHdYpFi9ezJ133gk463AuXbr0lDZVVVUk\nJSU1+T5VVVW88sor/u0zLZFkjDHh5MmkV7ijkPin4unwUAfin4qncMfZVVhQVXJzcxk6dCiff/45\nJSUlzJkzh717957UriVuSj8bkydPZty4cc16bXDS69ev30lVIdqKttbnxpjw8lzSK9xRyMQ3J7Kr\ndheKsqt2FxPfnHhWiW/Dhg107NiRyZMn+/f5fD6ysrIoKioiKyuLkSNH0qdPH44ePcqECRPIzMwk\nLS2NDRs2AKFL/hw+fJgbbrgBn89HUlLSKUuL1dfXEx8fz4EDB/z7EhIS2Lt3L2+++SYZGRmkpaUx\nbNiwUxIwOKWM5s2bB0BJSQk+nw+fz8eCBQv8baqqqsjKyiI9PZ309HR/Xb+ZM2eyceNGUlNTyc/P\nP6lE0tdff81NN91ESkoKmZmZbN++3f95jZVOalBXV8f48ePJyMggOTmZ/Px8AHbu3MmwYcPw+Xyk\np6fz+eefo6rMmDGDpKQkkpOT/f0T3Od1dXXMmDGD/v37k5KS0uz1Ro0x5792d5/e3W/fTdmexhc/\n3rR7E8fqTq4CcOT4EW77/W28WBK6tFDqZak89aPGF7IuLy+nb9++jT5fWlpKeXk5PXr04Mknn0RE\n2LRpE9XV1QwfPpyKioqQJX/WrVvHFVdcwdq1awFn/c5AHTp0YNSoUaxevZoJEyawefNm4uLi6N69\nO9deey2bNm1CRFi4cCFz587lySefbDTGCRMm8OyzzzJ48GBmzJjh33/ppZeyfv16IiMj+eyzzxg9\nejRbt27lscceY968ebz11luAk2gaPPDAA6SlpbFmzRree+89xo0b51+Q+nSlk8rKyqiurmbz5s1E\nR0f7E/qYMWOYOXMmubm5HD16lPr6el5//XXKysrYtm0b+/fvp3///gwePPiUPi8oKKBr165s2bKF\nY8eOMWjQIIYPH+6vSGGM8Q7PzfSCE97p9p8LAwYM8P+CLS4uZuzYsQBcffXVxMXFUVFRwTXXXMOj\njz7K448/zq5du+jcuTPJycmsX7+e++67j40bN4ZcSzMvL88/w1m+fDl5eXmAU+8uJyeH5ORknnji\nCT766KNG4ztw4AAHDhzwJ4yGIrIAx48f54477iA5OZmbb76Zjz/++LTft7i42P8e2dnZ1NTU8M03\n3wDflk7q1q2bv3RSoJ49e1JZWck999zD22+/TZcuXTh48CDV1dXk5uYCEBkZSVRUFMXFxYwePZqI\niAi6d+/OkCFD2LJlyyl9/u6777J06VJSU1PJyMigpqbGXzzXGOMt7W6m19SMDCD+qXh21Z5aWiiu\naxxF44ua9ZmJiYm89tprjT4fWGKoMaFK/mRnZ1NaWsq6deuYPXs2119/PTk5Of7lxR5++GFuvPFG\ndu7cyb59+1izZg2zZ88GnAKw06dPZ+TIkRQVFfHggw8267vl5+fTvXt3tm3bRn19PZGRkc16nwan\nK4t08cUXs23bNtasWcPzzz/PypUrG13ouimBfa6qPPPMM+Tk5DQ/cGNMu+C5md4j1z9CVMeTSwtF\ndYzikeubX1ooOzubY8eOnVS0dfv27WzcuPGUtllZWRQWOucPKyoq+OKLL/xlgYJL/nz55ZdERUUx\nduxYZsyYQWlpKRkZGZSVlVFWVsbIkSMREXJzc5k+fTq9e/fmkksuAU4uZbRkyZIm44+JiSEmJobi\n4mIAf3wN73P55ZfToUMHli1bRl1dHQDR0dEcPHgw5PsFfseioiK6detGly5dzqgv9+/fT319PaNG\njeJXv/oVpaWlREdHExsb66/afuzYMY4cOUJWVhYrVqygrq6Offv28f777zNgwIBT3jMnJ4fnnnuO\n48eP+/v98OHDZxSPMaZ98VzSG5M8hoIbC4jrGocgxHWNo+DGAsYkN7+0kIiwevVq/vCHP9CrVy8S\nExOZNWsWl1122Sltp0yZQn19PZmZmeTl5bF48WI6deoUsuTPjh07/Be3PPTQQ/5ZXLC8vDx++9vf\n+g9tgnPRyM0330zfvn39FdGbsmjRIqZOnUpqaiqBlTemTJnCkiVL8Pl8fPrpp/4ZVEpKChEREfh8\nPv/FJoGfXVJSQkpKCjNnzjxt0g1UXV3N0KFDGTRoEGPHjmXOnDkALFu2jKeffpqUlBQGDhzInj17\nyM3NJSUlBZ/PR3Z2NnPnzg3Z57fffjt9+vQhPT2dpKQkJk2aZFd1GuNRVlooTMJROud8YqWFGueF\n0jBnw/qnaV7oHystZIwxxmBJzxhjjIdY0jPGGOMZ7SbpnW/nJk3bYuPHGG9oF0kvMjKSmpoa+8Vl\nmkVVqampOet7EI0xbV+7uDk9NjaW3bt3s2/fvnCHcsaOHj1qv2Sb0Nr9ExkZSWxsbKt9njEmPFo0\n6YnIj4D5QASwUFUfC3p+MjAVqAMOARNV9fTrXAXp2LHjebeOYlFREWlpaeEOo82y/jHGtIQWO7wp\nIhHAAuDHQB9gtIj0CWr2iqomq2oqMBf4dUvFY4wxxrTkOb0BwE5VrVTVvwPLgVGBDVT1m4DNCwE7\nKWeMMabFtOThzSuBvwZs7wYyghuJyFRgOvA9ILsF4zHGGONxYb+QRVUXAAtE5FZgNvDT4DYiMhGY\n6G4eEpE/t2KILaUbsD/cQbRh1j+Ns75pmvVP07zQP3GNPdGSSa8a+EHAdqy7rzHLgedCPaGqBUBB\nqOfOVyKytbG14Yz1T1Osb5pm/dM0r/dPS57T2wIkiEgPEfkecAvwRmADEUkI2LwBsMqexhhjWkyL\nzfRU9YSI3Am8g3PLwsuq+pGIPAxsVdU3gDtFZBhwHPhfQhzaNMYYY86VFj2np6rrgHVB+/4z4PHP\nW/Lz27h2dbi2BVj/NM76pmnWP03zdP+cd/X0jDHGmOZqF2tvGmOMMWfCkl4rEJEfiMgGEflYRD4S\nkZ+7+78vIutF5DP374vDHWu4iEiEiHwoIm+52z1EZLOI7BSRFe7FUJ4kIjEi8pqIfCoin4jINTZ2\nHCIyzf2ZKheRV0Uk0stjR0ReFpGvRKQ8YF/IsSKOp91+2i4i6eGLvPVY0msdJ4B/V9U+QCYw1V2S\nbSbwR1VNAP7obnvVz4FPArYfB/JV9R9xLnK6LSxRtQ3zgbdV9WrAh9NPnh87InIlcBfQT1WTcC6Y\nuwVvj53FwI+C9jU2Vn4MJLh/JtLILWPtjSW9VqCqf1PVUvfxQZxfWlfiLMu2xG22BLgpPBGGl4jE\n4tyystDdFpzVeV5zm3i5b7oCg4GXAFT176p6ABs7DS4AOovIBUAU8Dc8PHZU9X3g66DdjY2VUcBS\ndWwCYkTk8taJNHws6bUyEYkH0oDNQHdV/Zv71B6ge5jCCrengHuBenf7EuCAqp5wt3fj/CfBi3oA\n+4BF7uHfhSJyITZ2UNVqYB7wBU6yqwVKsLETrLGxEmqpyHbfV5b0WpGIXAT8Drg7aLFt1LmM1nOX\n0orIT4CvVLUk3LG0URcA6cBzqpoGHCboUKaHx87FOLOVHsAVOIvWBx/aMwG8OlYCWdJrJSLSESfh\nFarq6+7uvQ2HE9y/vwpXfGE0CBgpIlU4S9Fl45zDinEPWcHpl7Brz3YDu1V1s7v9Gk4StLEDw4C/\nqOo+VT0OvI4znmzsnKyxsfJdl4psFyzptQL3HNVLwCeqGlgz8A2+XYXmp8DvWzu2cFPVWaoaq6rx\nOBchvKeqY4ANwL+4zTzZNwCqugf4q4hc5e66HvgYGzvgHNbMFJEo92esoW9s7JyssbHyBjDOvYoz\nE6gNOAzabtnN6a1ARK4FNgI7+Pa81X/gnNdbCfwQ2AX8q6oGn4T2DBEZCtyjqj8RkZ44M7/vAx8C\nY1X1WDjjCxcRScW5yOd7QCUwAec/rJ4fOyLyEJCHc4X0h8DtOOelPDl2RORVYChOJYW9wAPAGkKM\nFfc/Cs/iHBI+AkxQ1a3hiLs1WdIzxhjjGXZ40xhjjGdY0jPGGOMZlvSMMcZ4hiU9Y4wxnmFJzxhj\njGdY0jPGJSKXiEiZ+2ePiFQHbDe5Ur+I9BORp8/gM/507iIOPxEZLyLPhjsOY85Ui1ZON+Z8oqo1\nQCqAiDwIHFLVeQ3Pi8gFAWs6Br92K3Dae5xUdeC5idYY0xw20zOmCSKyWESeF5HNwFwRGSAi/+0u\n/vynhpVSRGRoQC3AB926ZkUiUikidwW836GA9kUBdfIK3ZuFEZER7r4St97ZWyHiihCRJ0Rki1sL\nbZK7f5qIvOw+TnbrzEU1Efd4EVnj1lmrEpE7RWS6226TiHzfbVckIvPdWW+5iAwIEdM/iMjv3Ji2\niMggd/+QgBnzhyISfU7/kYz5DmymZ8zpxQIDVbVORLoAWap6QkSGAY8C/xziNVcD1wHRwJ9F5Dl3\nfchAaUAi8CXwATBIRLYCLwCDVfUv7gobodyGs2xUfxHpBHwgIu/irFtaJCK5wP3AJFU9IiKfNhF3\nkhtLJLATuE9V00QkHxiHUwUDIEpVU0VkMPCy+7pA83Hq2BWLyA+Bd4DewD3AVFX9wF10/Wgj38mY\nFmdJz5jTW6Wqde7jrsASEUnAWa2+YyOvWesufXVMRL7CKeeyO6jN/6jqbgARKQPigUNApar+xW3z\nKk6Bz2DDgRQRaVhjsiuQ4CbK8cB24AVV/eAM4t7g1nk8KCK1wJvu/h1ASkC7V8Gp2SYiXUQkJiim\nYUAfd8IK0MVNch8AvxaRQuD1hu9sTDhY0jPm9A4HPP4lTpLIFac2YlEjrwlc67GO0D9rZ9KmMQL8\nTFXfCfFcAk7yvCJgX1NxB8ZRH7BdHxRT8JqFwdsdgExVDZ7JPSYia4ERODPSHFX9NNSXMqal2Tk9\nY76brnxbfmV8C7z/n4GebmICZzHlUN4B/k2cklWIyD+JyIXiVFp/Gqfa+iVBM8GzjTvP/axrcQ6t\n1gY9/y7ws4YNd6FsRKSXqu5Q1ceBLTiHfo0JC0t6xnw3c4E5IvIhLXCkRFX/D5gCvC0iJcBBnIrg\nwRbilNEpFZFynPOAFwD5wAJVrcA57/eYiFx6juI+6r7+efe9g90F9HMvrPkYmOzuv9u9+GU7cBz4\nr2Z+vjFnzaosGNPGiMhFqnrIvZpzAfCZquaHOaYinLJP7b70jGnfbKZnTNtzh3thy0c4hyVfCHM8\nxrQbNtMzxhjjGTbTM8YY4xmW9IwxxniGJT1jjDGeYUnPGGOMZ1jSM8YY4xmW9IwxxnjG/wM0Lf4S\nBg5kFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}