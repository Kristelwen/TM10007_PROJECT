{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2j6D84Om9fO53XZnvYDY3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kristelwen/TM10007_PROJECT/blob/master/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5frTx3De-hD",
        "colab_type": "text"
      },
      "source": [
        "## TM10007 Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlW924rpgGbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5412177b-7436-4cdf-a29e-aa56679b9dda"
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/Kristelwen/TM10007_PROJECT"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e11wSGohfFk_",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd46bOMwe3Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing modules\n",
        "# General packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from sklearn import datasets as ds\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Preprocessing packages\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# SVM Kernels\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "# Model selection\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Regularization\n",
        "from sklearn.linear_model import Lasso, RidgeClassifier\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTe-2RU5fK-q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54f3059e-c0a8-4836-d7c9-5ce13b6e3229"
      },
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "# from adni.load_data import load_data\n",
        "from brats.load_data import load_data\n",
        "#from hn.load_data import load_data\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 167\n",
            "The number of columns: 725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld6uTA6nfPb1",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYhZfj2YfQux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop columns which contain NaN values\n",
        "threshold = math.floor(len(data)/2)  # calculate threshold, half of total rows\n",
        "data_drop = data.dropna(thresh=threshold, axis=1)  # Delete columns/features with more than 'threshold' NaNs\n",
        "data_drop = data_drop.dropna(axis=0)  # Delete rows/subjects with NaNs\n",
        "\n",
        "# Split data and labels\n",
        "labels = data_drop['label']\n",
        "data_drop = data_drop.drop(columns=\"label\")  # Data without labels\n",
        "\n",
        "# Convert labels 'GBM' and 'LGG' to respectively 0 and 1\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Delete columns with strings (2 columns)\n",
        "# data_strings = data_drop.select_dtypes(include=[object])\n",
        "# columns_strings = list(data_strings.columns)\n",
        "# data_no_strings = data_drop.drop(columns_strings, axis=1)\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "#data_no_strings = data_no_strings.replace([np.inf, -np.inf], np.nan)\n",
        "# print(np.isinf(data_no_strings.values).any()) - check if dataframe contains infinity values\n",
        "\n",
        "# Split the data in a train (80%) and test set (20%) - OF MOET DIT VOOR FEATURE SCALING? Omdat je niks mag fitten op testdata\n",
        "data_train, data_test, label_train, label_test = train_test_split(data_drop, labels, test_size=0.1)\n",
        "data_train2, data_val, label_train2, label_val = train_test_split(data_train, label_train, test_size=0.1)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = RobustScaler()\n",
        "transformer = scaler.fit(data_train2.values)\n",
        "data_scaled_train2 = transformer.transform(data_train2.values)\n",
        "data_df_train2 = pd.DataFrame(data_scaled_train2, index = data_train2.index, columns = data_train2.columns)\n",
        "\n",
        "data_scaled_val = transformer.transform(data_val.values)\n",
        "data_df_val = pd.DataFrame(data_scaled_val, index = data_val.index, columns = data_val.columns)\n",
        "\n",
        "data_scaled_test = transformer.transform(data_test.values)\n",
        "data_df_test = pd.DataFrame(data_scaled_test, index = data_test.index, columns = data_test.columns)\n",
        "\n",
        "# Optie 1 feature selection: PCA\n",
        "  # Training set 2\n",
        "pca_train = PCA(n_components=80)  # Create a PCA with 20 components\n",
        "pca_train.fit(data_scaled_train2)  # Fit PCA\n",
        "data_train_pca2 = pca_train.transform(data_scaled_train2)  # Transform train data using PCA\n",
        "#df_train_pca2 = pd.DataFrame(data_train_pca2, index = data_scaled_train2.index)  # Put train data back in dataframe with 20 most important features\n",
        " \n",
        "  # Training set 1\n",
        "#data_train_pca = pca_train.transform(data_train)\n",
        "  # Validatie set\n",
        "data_val_pca = pca_train.transform(data_scaled_val)  # Transform test data using PCA\n",
        "\n",
        "  # Test set\n",
        "data_test_pca = pca_train.transform(data_scaled_test)  # Transform test data using PCA\n",
        "\n",
        "# Optie 2 feature selection: RFECV\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5mSqn3FfRg_",
        "colab_type": "text"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm0Pl-xthXat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing NN modules\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Cross-validation / performance\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scipy.stats import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6SX8BY3kiFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing -> train 1 wel scalen want cross validatie op toepassen\n",
        "transformer1 = scaler.fit(data_train.values)\n",
        "data_scaled_train = transformer1.transform(data_train.values)\n",
        "data_df_train = pd.DataFrame(data_scaled_train, index = data_train.index, columns = data_train.columns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P5nLVcXfS0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function definitions\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x, y):\n",
        "        self.input      = x\n",
        "        self.weights1   = np.random.rand(self.input.shape[1],4) \n",
        "        self.weights2   = np.random.rand(4,1)                 \n",
        "        self.y          = y\n",
        "        self.output     = np.zeros(self.y.shape)\n",
        "\n",
        "    def feedforward(self):\n",
        "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
        "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
        "\n",
        "    def backprop(self):\n",
        "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
        "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n",
        "        d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
        "\n",
        "        # update the weights with the derivative (slope) of the loss function\n",
        "        self.weights1 += d_weights1\n",
        "        self.weights2 += d_weights2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qngmmSa8srqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "b8b25d74-411f-4cbe-d764-fd2663e26da7"
      },
      "source": [
        "# Hyperparameter optimization of Neural Network\n",
        "\n",
        "# Our parameter to optimize is the number of estimators, which we vary uniformlybetween 1 and 400\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,), (7,2), (7,7,7),(9,9,9,9),(50,50,50,50), (50,50,50,50,50)],\n",
        "    'activation': ['logistic','identity','tanh'],  # relu \n",
        "    'solver': ['sgd', 'adam'],  # lbfgs\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],  # invscaling\n",
        "}\n",
        "# Now use the classifiers on all datasets\n",
        "fitted_mlps = list()\n",
        "    \n",
        "# Within a 5-fold cross-validation, try out 20 different number of trees\n",
        "clf = RandomizedSearchCV(MLPClassifier(max_iter=2000), parameter_space, cv=5, random_state=42, return_train_score=True)\n",
        "\n",
        "# Fit the classifier\n",
        "clf.fit(data_train, label_train)\n",
        "\n",
        "# Save for next part\n",
        "fitted_mlps.append(clf)\n",
        "\n",
        "# Get the best estimator and best parameters belonging to that estimator\n",
        "print('Best parameters found:\\n', clf.best_params_)\n",
        "# print(\"\")\n",
        "# All results\n",
        "# means = clf.cv_results_['mean_test_score']\n",
        "# stds = clf.cv_results_['std_test_score']\n",
        "# for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
        "\n",
        "# print(f'\\n The best estimator is {clf.best_estimator_} \\n The best amount of trees is {clf.best_params_}')\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:151: RuntimeWarning: invalid value encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:151: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:768: RuntimeWarning: invalid value encountered in greater\n",
            "  y = np.array(y > threshold, dtype=np.int)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            " {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (7, 7, 7), 'alpha': 0.05, 'activation': 'identity'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ATmAmAE2Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "d19e0ca4-a367-44d8-cc48-e06052afe58e"
      },
      "source": [
        "pd.DataFrame(clf.cv_results_)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_solver</th>\n",
              "      <th>param_learning_rate</th>\n",
              "      <th>param_hidden_layer_sizes</th>\n",
              "      <th>param_alpha</th>\n",
              "      <th>param_activation</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>split3_train_score</th>\n",
              "      <th>split4_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.370547</td>\n",
              "      <td>0.336066</td>\n",
              "      <td>0.004404</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>adam</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 2)</td>\n",
              "      <td>0.05</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'constant'...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.948804</td>\n",
              "      <td>0.950444</td>\n",
              "      <td>0.004881</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>sgd</td>\n",
              "      <td>constant</td>\n",
              "      <td>(100,)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>tanh</td>\n",
              "      <td>{'solver': 'sgd', 'learning_rate': 'constant',...</td>\n",
              "      <td>0.629630</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.687464</td>\n",
              "      <td>0.032529</td>\n",
              "      <td>9</td>\n",
              "      <td>0.817308</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.752381</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.790476</td>\n",
              "      <td>0.814890</td>\n",
              "      <td>0.040199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.410722</td>\n",
              "      <td>0.019928</td>\n",
              "      <td>0.004710</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>sgd</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 2)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>identity</td>\n",
              "      <td>{'solver': 'sgd', 'learning_rate': 'constant',...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.114645</td>\n",
              "      <td>0.085951</td>\n",
              "      <td>0.004419</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>adam</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>(7, 2)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>tanh</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'adaptive'...</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.573219</td>\n",
              "      <td>0.133358</td>\n",
              "      <td>10</td>\n",
              "      <td>0.509615</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.647619</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.570495</td>\n",
              "      <td>0.144315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.388168</td>\n",
              "      <td>0.471474</td>\n",
              "      <td>0.004444</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>adam</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 7, 7)</td>\n",
              "      <td>0.05</td>\n",
              "      <td>identity</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'constant'...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.717664</td>\n",
              "      <td>0.066428</td>\n",
              "      <td>1</td>\n",
              "      <td>0.971154</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.961905</td>\n",
              "      <td>0.923810</td>\n",
              "      <td>0.847619</td>\n",
              "      <td>0.927564</td>\n",
              "      <td>0.043630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.111796</td>\n",
              "      <td>0.031122</td>\n",
              "      <td>0.004343</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>adam</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 7, 7)</td>\n",
              "      <td>0.05</td>\n",
              "      <td>tanh</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'constant'...</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.709402</td>\n",
              "      <td>0.034188</td>\n",
              "      <td>2</td>\n",
              "      <td>0.759615</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.711923</td>\n",
              "      <td>0.024961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.260700</td>\n",
              "      <td>0.149117</td>\n",
              "      <td>0.004332</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>adam</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>(7, 2)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'adaptive'...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.332860</td>\n",
              "      <td>0.057417</td>\n",
              "      <td>0.004452</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>sgd</td>\n",
              "      <td>adaptive</td>\n",
              "      <td>(7, 7, 7)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'sgd', 'learning_rate': 'adaptive',...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.345172</td>\n",
              "      <td>0.023982</td>\n",
              "      <td>0.004582</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>sgd</td>\n",
              "      <td>constant</td>\n",
              "      <td>(7, 7, 7)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'sgd', 'learning_rate': 'constant',...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.694587</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>4</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.694652</td>\n",
              "      <td>0.001172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.351032</td>\n",
              "      <td>0.078825</td>\n",
              "      <td>0.005424</td>\n",
              "      <td>0.001152</td>\n",
              "      <td>adam</td>\n",
              "      <td>constant</td>\n",
              "      <td>(100,)</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>logistic</td>\n",
              "      <td>{'solver': 'adam', 'learning_rate': 'constant'...</td>\n",
              "      <td>0.703704</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.702279</td>\n",
              "      <td>0.028533</td>\n",
              "      <td>3</td>\n",
              "      <td>0.701923</td>\n",
              "      <td>0.695238</td>\n",
              "      <td>0.676190</td>\n",
              "      <td>0.704762</td>\n",
              "      <td>0.723810</td>\n",
              "      <td>0.700385</td>\n",
              "      <td>0.015376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n",
              "0       0.370547      0.336066  ...          0.694652         0.001172\n",
              "1       2.948804      0.950444  ...          0.814890         0.040199\n",
              "2       2.410722      0.019928  ...          0.694652         0.001172\n",
              "3       0.114645      0.085951  ...          0.570495         0.144315\n",
              "4       1.388168      0.471474  ...          0.927564         0.043630\n",
              "5       0.111796      0.031122  ...          0.711923         0.024961\n",
              "6       0.260700      0.149117  ...          0.694652         0.001172\n",
              "7       0.332860      0.057417  ...          0.694652         0.001172\n",
              "8       0.345172      0.023982  ...          0.694652         0.001172\n",
              "9       0.351032      0.078825  ...          0.700385         0.015376\n",
              "\n",
              "[10 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i31rjZMYhAI_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "0589fbdd-0941-4165-8885-19a3053846bf"
      },
      "source": [
        "# Fitting the Neural Network Classifier\n",
        "MLP = MLPClassifier(solver='adam', learning_rate='constant',hidden_layer_sizes=(9,9,9,9), alpha=0.0001, activation='identity')\n",
        "# MLP = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
        "                    # hidden_layer_sizes=(7, 2), random_state=1)\n",
        "MLP.fit(data_df_train2, label_train2)\n",
        "\n",
        "# Predictions\n",
        "train2_pred = MLP.predict(data_df_train2)\n",
        "val_pred = MLP.predict(data_df_val)\n",
        "train_pred = MLP.predict(data_df_train)\n",
        "\n",
        "# Errors\n",
        "error_train2 = (sum(abs(train2_pred - label_train2))/len(data_train2))*100\n",
        "error_train2 = (round(error_train2, 2))\n",
        "print ('The error for the training set is {}%'.format(error_train2))\n",
        "\n",
        "error_val = (sum(abs(val_pred - label_val))/len(data_val))*100\n",
        "error_val = (round(error_val, 2))\n",
        "print ('The error for the validation set is {}%'.format(error_val))\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "print('Confusion matrix and classification report of validation set')\n",
        "print(confusion_matrix(label_val, val_pred))\n",
        "print(classification_report(label_val, val_pred))\n",
        "\n",
        "print('Confusion matrix and classification report of training set')\n",
        "print(confusion_matrix(label_train2, train2_pred))\n",
        "print(classification_report(label_train2, train2_pred))\n",
        "\n",
        "print('Confusion matrix and classification report of bigger training set')\n",
        "print(confusion_matrix(label_train, train_pred))\n",
        "print(classification_report(label_train, train_pred))\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The error for the training set is 6.84%\n",
            "The error for the validation set is 14.29%\n",
            "Confusion matrix and classification report of validation set\n",
            "[[9 1]\n",
            " [1 3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90        10\n",
            "           1       0.75      0.75      0.75         4\n",
            "\n",
            "    accuracy                           0.86        14\n",
            "   macro avg       0.82      0.82      0.82        14\n",
            "weighted avg       0.86      0.86      0.86        14\n",
            "\n",
            "Confusion matrix and classification report of training set\n",
            "[[79  2]\n",
            " [ 6 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95        81\n",
            "           1       0.94      0.83      0.88        36\n",
            "\n",
            "    accuracy                           0.93       117\n",
            "   macro avg       0.93      0.90      0.92       117\n",
            "weighted avg       0.93      0.93      0.93       117\n",
            "\n",
            "Confusion matrix and classification report of bigger training set\n",
            "[[86  5]\n",
            " [ 4 36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95        91\n",
            "           1       0.88      0.90      0.89        40\n",
            "\n",
            "    accuracy                           0.93       131\n",
            "   macro avg       0.92      0.92      0.92       131\n",
            "weighted avg       0.93      0.93      0.93       131\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewcFR2-4pidS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f9f23208-919a-4ddb-c45f-8b1b9058de98"
      },
      "source": [
        "# Evaluate neural network using three-fold cross-validation\n",
        "score = cross_val_score(MLP, data_df_train, label_train, cv=3)\n",
        "\n",
        "print(f'The accuracy of the validation set in the different folds is {score}')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the validation set in the different folds is [0.84090909 0.81818182 0.86046512]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}