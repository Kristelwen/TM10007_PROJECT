{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "begin_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kristelwen/TM10007_PROJECT/blob/master/begin_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "d98db171-9bf6-43a4-80c5-88f299b22478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/karinvangarderen/tm10007_project.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySDv5ko54ViJ",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Lae4Zh5V3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "b91abbc3-09c5-451d-d999-d59502ccaa87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Data loading functions. Uncomment the one you want to use\n",
        "# from adni.load_data import load_data\n",
        "from brats.load_data import load_data\n",
        "#from hn.load_data import load_data\n",
        "# hoi\n",
        "# en als ik dit type?\n",
        "\n",
        "data = load_data()\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of samples: 167\n",
            "The number of columns: 725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50S8Z8Y968kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_top = data.head()  \n",
        "\n",
        "# display  \n",
        "# data_top # = show data_top"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwfkNzjB8GFQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Outline opdracht\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Gebaseerd op beeldvorming moeten we eruit kunnen halen wat voor een soort tumor het is?\n",
        "Je wil weten of het HIGH of LOW grade is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl2rwSBvHPjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing the data \n",
        "\n",
        "# Split data and labels\n",
        "labels = data['label']\n",
        "data2 = data.drop(columns=\"label\")  # Data without labels --> kolom labels is weggehaald\n",
        "\n",
        "# Convert labels 'GBM' and 'LGG' to respectively 0 and 1 --> BGM = 0, LGG = 1\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Delete columns with strings (2 columns)\n",
        "data_strings = data2.select_dtypes(include=[object])\n",
        "columns_strings = list(data_strings.columns)\n",
        "data_no_strings = data2.drop(columns_strings, axis=1)\n",
        "\n",
        "# Replace infinity values with NaN\n",
        "data_no_strings = data_no_strings.replace([np.inf, -np.inf], np.nan)\n",
        "# print(np.isinf(data_no_strings.values).any()) - check if dataframe contains infinity values\n",
        "\n",
        "# Drop columns which contain NaN values\n",
        "data_drop = data_no_strings.dropna(axis=1)\n",
        "\n",
        "# Feature scaling\n",
        "standard_scaler = StandardScaler()\n",
        "data_scaled = standard_scaler.fit_transform(data_drop.values)\n",
        "data_df = pd.DataFrame(data_scaled, index = data_drop.index, columns = data_drop.columns)\n",
        "\n",
        "# Split the data in a train (80%) and test set (20%) --> evt aanpassing dmv cross-validation\n",
        "data_train, data_test, label_train, label_test = train_test_split(data_df, labels, test_size=0.2)\n",
        "\n",
        "# PCA\n",
        "pca_train = PCA(n_components=20)  # Create a PCA with 20 components --> willen we er 20??\n",
        "pca_train.fit(data_train)  # Fit PCA\n",
        "data_train_pca = pca_train.transform(data_train)  # Transform train data using PCA\n",
        "df_train_pca = pd.DataFrame(data_train_pca, index = data_train.index)  # Put train data back in dataframe with 20 most important features\n",
        "# print(df_train_pca)\n",
        "\n",
        "data_test_pca = pca_train.transform(data_test)  # Transform test data using PCA\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TlOEntcHLdo",
        "colab_type": "text"
      },
      "source": [
        "Vanaf hier begin van SVM. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UaR64n7HNwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "397bdfdd-9e42-4c5e-95ce-1db0b0ba403b"
      },
      "source": [
        "!pip install SimpleITK \n",
        "# General packages\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import SimpleITK as sitk\n",
        "\n",
        "# Classifiers and kernels\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.6/dist-packages (1.2.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twjsXGFvIJqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "e0cb1721-0638-4293-e818-dff67c44a687"
      },
      "source": [
        "# Construct classifiers\n",
        "svmlin = SVC(kernel='linear', gamma='scale')  # linear kernel\n",
        "svmrbf = SVC(kernel='rbf', gamma='scale')  # radial basis function kernel\n",
        "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')  # polynomial kernel\n",
        "\n",
        "clsfs = [svmlin, svmpoly, svmrbf] # verschillende classifiers\n",
        "\n",
        "# svmlin\n",
        "svmlin.fit(data_train_pca, label_train) # fit classifier op trainingsset\n",
        "test = svmlin.predict(data_test_pca) # test classifier op testset\n",
        "error = sum(abs(test - label_test)) # hoevaak komt het niet overeen met het gegven label?\n",
        "print(f'Misclassified with linear kernel: {error}/{len(test)}')\n",
        "\n",
        "# svmrbf\n",
        "svmrbf.fit(data_train_pca, label_train) # fit classifier op trainingsset\n",
        "test = svmrbf.predict(data_test_pca) # test classifier op testset\n",
        "error = sum(abs(test - label_test)) # hoevaak komt het niet overeen met het gegven label?\n",
        "print(f'Misclassified with rbf kernel: {error}/{len(test)}')\n",
        "\n",
        "# svmpoly\n",
        "svmpoly.fit(data_train_pca, label_train) # fit classifier op trainingsset\n",
        "test = svmpoly.predict(data_test_pca) # test classifier op testset\n",
        "error = sum(abs(test - label_test)) # hoevaak komt het niet overeen met het gegven label?\n",
        "print(f'Misclassified with poly kernel: {error}/{len(test)}')\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassified with linear kernel: 3/34\n",
            "Misclassified with rbf kernel: 3/34\n",
            "Misclassified with poly kernel: 4/34\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}